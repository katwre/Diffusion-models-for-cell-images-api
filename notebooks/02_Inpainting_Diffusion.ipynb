{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2 - Inpainting Diffusion\n",
        "\n",
        "The model is trained to predict the noise \\(\\epsilon\\) using the standard diffusion objective.\n",
        "\n",
        "Conditioning information is provided via:\n",
        "\n",
        "- the masked clean image $x_{0,\\text{masked}}$\n",
        "  (context),\n",
        "\n",
        "- the binary mask $m$ where $m = 1$ indicates pixels that are missing and should be inpainted,\n",
        "\n",
        "- and the current noisy image $x_t$ at diffusion step $t$.\n",
        "\n",
        "During sampling, known pixels are clamped after every reverse diffusion step to enforce consistency with the observed image.\n",
        "\n",
        "\n",
        "What \"success\" could look like to me:\n",
        "\n",
        "- Known pixels are exactly preserved (hard clamp)\n",
        "- Missing region gradually becomes plausible:\n",
        "  - correct H&E colors\n",
        "  - compatible morphology with surrounding context\n",
        "- Early on it may be blurry; that improves with training."
      ],
      "metadata": {
        "id": "su7CUjCeQeyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# Standard library\n",
        "# ============================\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import math\n",
        "from pathlib import Path\n",
        "from itertools import product\n",
        "\n",
        "# ============================\n",
        "# Scientific / data libraries\n",
        "# ============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ============================\n",
        "# Visualization\n",
        "# ============================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================\n",
        "# Image handling\n",
        "# ============================\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# ============================\n",
        "# PyTorch core\n",
        "# ============================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# ============================\n",
        "# PyTorch data utilities\n",
        "# ============================\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ============================\n",
        "# Torchvision\n",
        "# ============================\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n"
      ],
      "metadata": {
        "id": "87HKHvlNQe4R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "os.chdir(\"drive/MyDrive/Diffusionmodelsforcellimages/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUeKXBOQhfT",
        "outputId": "b0b52d9a-7ad4-402b-be6b-cbe8f24ba8bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader\n",
        "class PBCCellDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        \"\"\"\n",
        "        root_dir: path to e.g. 'train/' directory\n",
        "        \"\"\"\n",
        "        self.root_dir = Path(root_dir)\n",
        "\n",
        "        # Collect all image paths recursively\n",
        "        self.image_paths = sorted( p for p in self.root_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "        if len(self.image_paths) == 0:\n",
        "            raise RuntimeError(f\"No images found in {root_dir}\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            #transforms.Resize((64, image_size)),\n",
        "            #transforms.RandomHorizontalFlip() # it's not really needed for HandE images, cells are roughly rotationally symmetric\n",
        "            transforms.ToTensor(),                 # scales data to [0, 1]\n",
        "            transforms.Lambda(lambda t: t * 2 - 1) # scales data to [-1, 1]\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        x0 = self.transform(img)\n",
        "        return x0\n",
        "\n",
        "\n",
        "ds = PBCCellDataset(\n",
        "    root_dir=\"data/PBC_dataset_normal_DIB_64x64/\")\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "dl = DataLoader(\n",
        "    ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,              # 4–8?\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,    # keeps workers alive across epochs\n",
        "    prefetch_factor=2\n",
        ")"
      ],
      "metadata": {
        "id": "wvXyUfi2ZL94"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a mask generator (random rectangle). Mask convention:\n",
        "\n",
        "- mask = 1 for pixels to inpaint (missing)\n",
        "- mask = 0 for known pixels"
      ],
      "metadata": {
        "id": "wvNHYr-DSB60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def random_rect_mask(batch_size, H, W, min_frac=0.2, max_frac=0.5, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Returns mask of shape (B, 1, H, W) with 1 in a random rectangle (missing region).\n",
        "    \"\"\"\n",
        "    masks = torch.zeros((batch_size, 1, H, W), device=device)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        rh = int(random.uniform(min_frac, max_frac) * H)\n",
        "        rw = int(random.uniform(min_frac, max_frac) * W)\n",
        "\n",
        "        y0 = random.randint(0, H - rh)\n",
        "        x0 = random.randint(0, W - rw)\n",
        "\n",
        "        masks[b, :, y0:y0+rh, x0:x0+rw] = 1.0\n",
        "\n",
        "    return masks\n"
      ],
      "metadata": {
        "id": "Sd0LAFhsSNHt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I am gonna modify the model input channels. Instead of input $x_t$ alone (3 channels), I will feed:\n",
        "\n",
        "$$\n",
        "\\text{model input} = \\operatorname{concat}\\left(x_t,\\; x_{0,\\text{masked}},\\; m\\right)\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $x_t: (B, 3, H, W)$\n",
        "\n",
        "- $x_{0,\\text{masked}}: (B, 3, H, W)$\n",
        "\n",
        "- $mask: (B, 1, H, W)$\n",
        "\n",
        "So, in total: 7 channels\n",
        "\n",
        "This is a very standard conditioning pattern and tends to be more stable than trying to encode conditioning only by replacing pixels."
      ],
      "metadata": {
        "id": "9aBlPmObTKYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear beta schedule; linear noise schedule\n",
        "def linear_beta_schedule(T, beta_start=1e-4, beta_end=2e-2, device=\"cpu\"):\n",
        "    betas = torch.linspace(beta_start, beta_end, T, device=device) # define the noise schedule\n",
        "    alphas = 1.0 - betas # used in reverse updates\n",
        "    alpha_bars = torch.cumprod(alphas, dim=0) # compute cumulative signal retention; used in both forward diffusion and reverse sampling\n",
        "    return betas, alphas, alpha_bars\n",
        "\n",
        "T = 1000\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "betas, alphas, alpha_bars = linear_beta_schedule(T, device=device)\n",
        "\n",
        "def sinusoidal_time_embedding(timesteps: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Create sinusoidal timestep embeddings.\n",
        "    IT describes the position of an index in an ordered list.\n",
        "\n",
        "    Args:\n",
        "        timesteps: Tensor of shape (B,) containing integer timesteps.\n",
        "        dim: Dimension of the embedding.\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape (B, dim) with sinusoidal embeddings.\n",
        "    \"\"\"\n",
        "    # Ensure timesteps are floats\n",
        "    timesteps = timesteps.float()\n",
        "\n",
        "    device = timesteps.device\n",
        "    half_dim = dim // 2\n",
        "\n",
        "    # Compute the frequencies\n",
        "    exponent = -math.log(10000) / (half_dim - 1)\n",
        "    frequencies = torch.exp(\n",
        "        torch.arange(half_dim, device=device) * exponent\n",
        "    )\n",
        "\n",
        "    # Outer product: (B, half_dim)\n",
        "    args = timesteps[:, None] * frequencies[None, :]\n",
        "\n",
        "    # Sinusoidal embedding\n",
        "    embedding = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
        "\n",
        "    # Pad if dim is odd\n",
        "    if dim % 2 == 1:\n",
        "        embedding = torch.nn.functional.pad(embedding, (0, 1))\n",
        "\n",
        "    return embedding\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_dim):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.GroupNorm(8, in_ch) # its' kind of BatchNorm\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "\n",
        "        self.norm2 = nn.GroupNorm(8, out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "\n",
        "        self.time_proj = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_dim, out_ch)\n",
        "        )\n",
        "\n",
        "        self.skip = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
        "        # Add time channel\n",
        "        h = h + self.time_proj(t_emb)[:, :, None, None]\n",
        "        h = self.conv2(F.silu(self.norm2(h)))\n",
        "        return h + self.skip(x)\n",
        "\n",
        "\n",
        "\n",
        "class UNetSmall(nn.Module):\n",
        "    def __init__(self, in_ch=3, base_ch=64, time_dim=256):\n",
        "        super().__init__()\n",
        "        self.time_dim = time_dim\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "        )\n",
        "\n",
        "        self.conv_in = nn.Conv2d(in_ch, base_ch, 3, padding=1)\n",
        "\n",
        "        # Down\n",
        "        self.rb1 = ResBlock(base_ch, base_ch, time_dim)\n",
        "        self.down1 = nn.Conv2d(base_ch, base_ch, 4, 2, 1)       # /2\n",
        "\n",
        "        self.rb2 = ResBlock(base_ch, base_ch*2, time_dim)\n",
        "        self.down2 = nn.Conv2d(base_ch*2, base_ch*2, 4, 2, 1)   # /4\n",
        "\n",
        "        self.rb3 = ResBlock(base_ch*2, base_ch*4, time_dim)\n",
        "        self.down3 = nn.Conv2d(base_ch*4, base_ch*4, 4, 2, 1)   # /8\n",
        "\n",
        "        # Middle\n",
        "        self.mid1 = ResBlock(base_ch*4, base_ch*4, time_dim)\n",
        "        self.mid2 = ResBlock(base_ch*4, base_ch*4, time_dim)\n",
        "\n",
        "        # Up\n",
        "        self.up3 = nn.ConvTranspose2d(base_ch*4, base_ch*4, 4, 2, 1)  # x2\n",
        "        self.urb3 = ResBlock(base_ch*8, base_ch*2, time_dim)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(base_ch*2, base_ch*2, 4, 2, 1)  # x4\n",
        "        self.urb2 = ResBlock(base_ch*4, base_ch, time_dim)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(base_ch, base_ch, 4, 2, 1)      # x8\n",
        "        self.urb1 = ResBlock(base_ch*2, base_ch, time_dim)\n",
        "\n",
        "        self.conv_out = nn.Sequential(\n",
        "            nn.GroupNorm(8, base_ch),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(base_ch, 3, 3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        t_emb = sinusoidal_time_embedding(t, self.time_dim)\n",
        "        t_emb = self.time_mlp(t_emb)\n",
        "\n",
        "        x0 = self.conv_in(x)\n",
        "        x1 = self.rb1(x0, t_emb)\n",
        "        d1 = self.down1(x1)\n",
        "\n",
        "        x2 = self.rb2(d1, t_emb)\n",
        "        d2 = self.down2(x2)\n",
        "\n",
        "        x3 = self.rb3(d2, t_emb)\n",
        "        d3 = self.down3(x3)\n",
        "\n",
        "        m = self.mid1(d3, t_emb)\n",
        "        m = self.mid2(m, t_emb)\n",
        "\n",
        "        u3 = self.up3(m)\n",
        "        u3 = torch.cat([u3, x3], dim=1)\n",
        "        u3 = self.urb3(u3, t_emb)\n",
        "\n",
        "        u2 = self.up2(u3)\n",
        "        u2 = torch.cat([u2, x2], dim=1)\n",
        "        u2 = self.urb2(u2, t_emb)\n",
        "\n",
        "        u1 = self.up1(u2)\n",
        "        u1 = torch.cat([u1, x1], dim=1)\n",
        "        u1 = self.urb1(u1, t_emb)\n",
        "\n",
        "        return self.conv_out(u1)  # predicts epsilon\n"
      ],
      "metadata": {
        "id": "PXeonMivY25h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the UNetSmall init:"
      ],
      "metadata": {
        "id": "Bk3i-bA0Uj6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNetSmall(in_ch=7, base_ch=64, time_dim=256).to(device)"
      ],
      "metadata": {
        "id": "9dMLnOTjUoZ9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop for inpainting ($ε$-prediction remains unchanged). Key steps per batch:\n",
        "\n",
        "- Sample a random mask mask\n",
        "- Create $x_{0,\\text{masked}}$ (missing region set to 0 or noise)\n",
        "\n",
        "Sample timestep $t$:\n",
        "\n",
        "- Create $x_t$ by forward noising the full $x_0$\n",
        "- Feed $concat(x_t, x_{0,\\text{masked}}, mask)$ into model\n",
        "- Predict noise and compute MSE loss vs true $ε$\n",
        "\n",
        "\n",
        "Edit:\n",
        "To encourage the model to focus on reconstructing the missing regions during inpainting, I use a weighted noise-prediction loss that emphasizes pixels inside the masked area. Specifically, the training objective is defined as\n",
        "\n",
        "$$\n",
        "\\mathcal{L}\n",
        "=\n",
        "\\mathbb{E}\\Big[\n",
        "(\\hat{\\epsilon} - \\epsilon)^2 \\cdot \\big(1 + (w_{\\text{missing}} - 1)\\, m\\big)\n",
        "\\Big],\n",
        "$$\n",
        "\n",
        "where $\\hat{\\epsilon}$ is the model’s predicted noise, $\\epsilon$ is the true noise added during the forward diffusion process, \\(m\\) is a binary mask indicating missing pixels ($m = 1$) versus known pixels ($m = 0$), and $w_{\\text{missing}}$ is a scalar hyperparameter controlling the relative importance of the masked region. This weighting scheme increases the contribution of errors inside the missing region while preserving standard noise-prediction training on known pixels, leading to more coherent and structure-aware inpainting results.\n"
      ],
      "metadata": {
        "id": "2QKVVPx3Xm7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Iloss_fn = nn.MSELoss()\n",
        "opt = optim.AdamW(model.parameters(), lr=2e-4)\n",
        "\n",
        "# Precompute these once for speed (as I did in Phase 1)\n",
        "sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
        "sqrt_one_minus_alpha_bars = torch.sqrt(1.0 - alpha_bars)\n",
        "\n",
        "def q_sample_batch(x0, t, sqrt_alpha_bars, sqrt_one_minus_alpha_bars):\n",
        "    B = x0.shape[0]\n",
        "    sa = sqrt_alpha_bars[t].view(B, 1, 1, 1)\n",
        "    so = sqrt_one_minus_alpha_bars[t].view(B, 1, 1, 1)\n",
        "    eps = torch.randn_like(x0)\n",
        "    xt = sa * x0 + so * eps\n",
        "    return xt, eps\n",
        "\n",
        "EPOCHS = 30\n",
        "model.train()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    pbar = tqdm(dl, desc=f\"Phase2 epoch {epoch+1}/{EPOCHS}\")\n",
        "    running = 0.0\n",
        "\n",
        "    for step, x0 in enumerate(pbar):\n",
        "        x0 = x0.to(device, non_blocking=True)  # (B,3,H,W) in [-1,1]\n",
        "        B, C, H, W = x0.shape\n",
        "\n",
        "        # 1) sample mask (1 = missing)\n",
        "        mask = random_rect_mask(B, H, W, min_frac=0.2, max_frac=0.5, device=device)\n",
        "\n",
        "        # 2) masked clean context (set missing region to 0)\n",
        "        x0_masked = x0 * (1.0 - mask)\n",
        "\n",
        "        # 3) sample t\n",
        "        t = torch.randint(0, T, (B,), device=device).long()\n",
        "\n",
        "        # 4) forward diffuse the full x0 -> xt\n",
        "        xt, eps = q_sample_batch(x0, t, sqrt_alpha_bars, sqrt_one_minus_alpha_bars)\n",
        "\n",
        "        # 5) model input: concat(xt, x0_masked, mask) -> (B,7,H,W)\n",
        "        model_in = torch.cat([xt, x0_masked, mask], dim=1)\n",
        "\n",
        "        # 6) predict noise, compute loss\n",
        "        eps_hat = model(model_in, t)\n",
        "        #loss = loss_fn(eps_hat, eps)\n",
        "        # calcualte weighted loss instead, so missing region contributes ~x× more gradient\n",
        "        w_missing = 10\n",
        "        # pixel-wise squared error\n",
        "        mse = (eps_hat - eps) ** 2  # (B,3,H,W)\n",
        "\n",
        "        # expand mask to match channels\n",
        "        mask_c = mask.expand_as(mse)  # (B,3,H,W)\n",
        "\n",
        "        # weighted loss\n",
        "        loss = (mse * (1.0 + (w_missing - 1.0) * mask_c)).mean()\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        running += loss.item()\n",
        "        if step % 50 == 0:\n",
        "            pbar.set_postfix(loss=running / (step + 1))\n",
        "\n",
        "    print(f\"Epoch {epoch+1} mean loss: {running / len(dl):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IlEl8KLYIW8",
        "outputId": "47a737ba-7fa4-427e-90c0-2ed1efaa4b57"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 1/30: 100%|██████████| 602/602 [00:37<00:00, 15.90it/s, loss=0.0205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 mean loss: 0.0205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 2/30: 100%|██████████| 602/602 [00:38<00:00, 15.68it/s, loss=0.0196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 mean loss: 0.0196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 3/30: 100%|██████████| 602/602 [00:38<00:00, 15.47it/s, loss=0.0214]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 mean loss: 0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 4/30: 100%|██████████| 602/602 [00:39<00:00, 15.37it/s, loss=0.0212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 mean loss: 0.0212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 5/30: 100%|██████████| 602/602 [00:39<00:00, 15.23it/s, loss=0.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 mean loss: 0.0200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 6/30: 100%|██████████| 602/602 [00:39<00:00, 15.15it/s, loss=0.0194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 mean loss: 0.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 7/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.019]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 mean loss: 0.0190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 8/30: 100%|██████████| 602/602 [00:40<00:00, 15.05it/s, loss=0.0195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 mean loss: 0.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 9/30: 100%|██████████| 602/602 [00:39<00:00, 15.06it/s, loss=0.0221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 mean loss: 0.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 10/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.019]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 mean loss: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 11/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.0196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 mean loss: 0.0196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 12/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.0196]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 mean loss: 0.0196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 13/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.0198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 mean loss: 0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 14/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.0208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 mean loss: 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 15/30: 100%|██████████| 602/602 [00:39<00:00, 15.05it/s, loss=0.0199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 mean loss: 0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 16/30: 100%|██████████| 602/602 [00:40<00:00, 15.03it/s, loss=0.0177]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 mean loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 17/30: 100%|██████████| 602/602 [00:39<00:00, 15.06it/s, loss=0.0198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 mean loss: 0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 18/30: 100%|██████████| 602/602 [00:39<00:00, 15.06it/s, loss=0.0195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 mean loss: 0.0196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 19/30: 100%|██████████| 602/602 [00:39<00:00, 15.07it/s, loss=0.0195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 mean loss: 0.0195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 20/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.0211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 mean loss: 0.0210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 21/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.0188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 mean loss: 0.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 22/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.0193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 mean loss: 0.0192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 23/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.0206]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 mean loss: 0.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 24/30: 100%|██████████| 602/602 [00:39<00:00, 15.11it/s, loss=0.0191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 mean loss: 0.0192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 25/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.0206]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 mean loss: 0.0205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 26/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.0187]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 mean loss: 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 27/30: 100%|██████████| 602/602 [00:39<00:00, 15.09it/s, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 mean loss: 0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 28/30: 100%|██████████| 602/602 [00:39<00:00, 15.07it/s, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 mean loss: 0.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 29/30: 100%|██████████| 602/602 [00:39<00:00, 15.07it/s, loss=0.0197]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 mean loss: 0.0197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Phase2 epoch 30/30: 100%|██████████| 602/602 [00:39<00:00, 15.08it/s, loss=0.0191]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 mean loss: 0.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inpainting sampling with clamping (the key Phase 2 idea).\n",
        "\n",
        "We provide a specific image $x0$ and a mask. Then sample starting from noise, and after every reverse step overwrite the known pixels. Clamping rule (hard clamp in normalized space):\n",
        "\n",
        "- known = 1 - mask\n",
        "- after each update: $x_t←x_t⋅mask+x_0⋅(1 - mask)$"
      ],
      "metadata": {
        "id": "ogpnFUx0YQZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alpha_bar_{t-1}\n",
        "alpha_bars_prev = torch.cat(\n",
        "    [torch.tensor([1.0], device=device), alpha_bars[:-1]]\n",
        ")\n",
        "# posterior variance (DDPM)\n",
        "posterior_variance = betas * (1.0 - alpha_bars_prev) / (1.0 - alpha_bars)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def ddpm_inpaint_noised_clamp(\n",
        "    model, x0, mask,\n",
        "    T, betas, alphas, alpha_bars, posterior_variance,\n",
        "    device\n",
        "):\n",
        "    model.eval()\n",
        "    B, C, H, W = x0.shape\n",
        "    x = torch.randn_like(x0)\n",
        "\n",
        "    for t in reversed(range(T)):\n",
        "        t_batch = torch.full((B,), t, device=device, dtype=torch.long)\n",
        "\n",
        "        # compute the correct known-pixels state at this timestep\n",
        "        ab = alpha_bars[t]\n",
        "        eps_known = torch.randn_like(x0)  # fresh noise for known region\n",
        "        x_known_t = torch.sqrt(ab) * x0 + torch.sqrt(1 - ab) * eps_known\n",
        "\n",
        "        # clamp known pixels at the correct noise level\n",
        "        x = x * mask + x_known_t * (1.0 - mask)\n",
        "\n",
        "        # conditioning (same as training)\n",
        "        x0_masked = x0 * (1.0 - mask)\n",
        "        model_in = torch.cat([x, x0_masked, mask], dim=1)\n",
        "\n",
        "        eps_hat = model(model_in, t_batch)\n",
        "\n",
        "        beta_t = betas[t]\n",
        "        alpha_t = alphas[t]\n",
        "        alpha_bar_t = alpha_bars[t]\n",
        "\n",
        "        mean = (1.0 / torch.sqrt(alpha_t)) * (x - (beta_t / torch.sqrt(1.0 - alpha_bar_t)) * eps_hat)\n",
        "\n",
        "        if t > 0:\n",
        "            z = torch.randn_like(x)\n",
        "            x = mean + torch.sqrt(posterior_variance[t]) * z\n",
        "        else:\n",
        "            x = mean\n",
        "\n",
        "    # final hard clamp to clean known pixels\n",
        "    x = x * mask + x0 * (1.0 - mask)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5me8jlCYYg9R"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization before and after"
      ],
      "metadata": {
        "id": "XI-wuMEkYhtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(x, title=\"\"):\n",
        "    x = (x.squeeze(0).clamp(-1,1) + 1) / 2  # to [0,1]\n",
        "    plt.imshow(x.detach().cpu().permute(1,2,0))\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# pick one example\n",
        "x0 = ds[0].unsqueeze(0).to(device)\n",
        "B, C, H, W = x0.shape\n",
        "mask = random_rect_mask(1, H, W, min_frac=0.3, max_frac=0.4, device=device)\n",
        "\n",
        "x0_masked = x0 * (1.0 - mask)\n",
        "\n",
        "x_inpaint = ddpm_inpaint(\n",
        "    model=model,\n",
        "    x0=x0,\n",
        "    mask=mask,\n",
        "    T=T,\n",
        "    betas=betas,\n",
        "    alphas=alphas,\n",
        "    alpha_bars=alpha_bars,\n",
        "    posterior_variance=posterior_variance,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,3,1); show_img(x0, \"Original x0\")\n",
        "plt.subplot(1,3,2); show_img(x0_masked, \"Masked (conditioning)\")\n",
        "plt.subplot(1,3,3); show_img(x_inpaint, \"Inpainted sample\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "V89Vq4aIYjgn",
        "outputId": "67c0196d-3799-410b-b60c-96beb27fa848"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"checkpoints/phase2_inpaint_unet.pt\"\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "torch.save(\n",
        "    {\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"config\": {\n",
        "            \"in_ch\": 7,\n",
        "            \"base_ch\": 64,\n",
        "            \"time_dim\": 256,\n",
        "            \"image_size\": 64,\n",
        "            \"T\": T,\n",
        "        },\n",
        "    },\n",
        "    save_path\n",
        ")\n",
        "\n",
        "print(f\"Model saved to {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8-wLTnY7DCX",
        "outputId": "88a33f79-571a-483f-a313-c7a701f5994a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to checkpoints/phase2_inpaint_unet.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U onnx onnxruntime onnxscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-JWh_Ow8f-V",
        "outputId": "fecd5949-4d6e-4dd5-e616-13d401a301bc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.20.0)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, onnx_ir, onnxscript\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx_ir-0.1.13 onnxruntime-1.23.2 onnxscript-0.5.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_x = torch.randn(1, 7, 64, 64, device=device)\n",
        "dummy_t = torch.tensor([10], device=device)\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (dummy_x, dummy_t),\n",
        "    \"checkpoints/unet_inpaint.onnx\",\n",
        "    input_names=[\"x\", \"t\"],\n",
        "    output_names=[\"eps_hat\"],\n",
        "    dynamic_axes={\n",
        "        \"x\": {0: \"batch\"},\n",
        "        \"t\": {0: \"batch\"},\n",
        "        \"eps_hat\": {0: \"batch\"},\n",
        "    },\n",
        "    opset_version=17,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-K9cqUT8ACE",
        "outputId": "4c4a622e-c8ea-4f40-ad54-28e64e125a13"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-704902495.py:4: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W1226 18:36:12.109000 1898 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `UNetSmall([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `UNetSmall([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 17 of general pattern rewrite rules.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 17},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.0+cu126',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"x\"<FLOAT,[s13,7,64,64]>,\n",
              "                %\"t\"<INT64,[s13]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"eps_hat\"<FLOAT,[s13,3,64,64]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"time_mlp.0.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"time_mlp.2.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"conv_in.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"rb1.conv1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"rb1.conv2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"rb1.time_proj.1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"down1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"rb2.conv1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"rb2.conv2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"rb2.time_proj.1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"rb2.skip.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"down2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"rb3.conv1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"rb3.conv2.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"rb3.time_proj.1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"rb3.skip.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"down3.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"mid1.conv1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"mid1.conv2.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"mid1.time_proj.1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"mid2.conv1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"mid2.conv2.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"mid2.time_proj.1.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"up3.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
              "                %\"urb3.conv1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"urb3.conv2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"urb3.time_proj.1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"urb3.skip.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"up2.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
              "                %\"urb2.conv1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb2.conv2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb2.time_proj.1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb2.skip.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"up1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb1.conv1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb1.conv2.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb1.time_proj.1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"urb1.skip.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
              "                %\"conv_out.2.bias\"<FLOAT,[3]>{TorchTensor<FLOAT,[3]>(Parameter containing: tensor([-0.0287,  0.0075, -0.0041], device='cuda:0', requires_grad=True), name='conv_out.2.bias')},\n",
              "                %\"time_mlp.0.weight\"<FLOAT,[256,256]>{TorchTensor(...)},\n",
              "                %\"time_mlp.2.weight\"<FLOAT,[256,256]>{TorchTensor(...)},\n",
              "                %\"conv_in.weight\"<FLOAT,[64,7,3,3]>{TorchTensor(...)},\n",
              "                %\"rb1.conv1.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
              "                %\"rb1.conv2.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
              "                %\"rb1.time_proj.1.weight\"<FLOAT,[64,256]>{TorchTensor(...)},\n",
              "                %\"down1.weight\"<FLOAT,[64,64,4,4]>{TorchTensor(...)},\n",
              "                %\"rb2.conv1.weight\"<FLOAT,[128,64,3,3]>{TorchTensor(...)},\n",
              "                %\"rb2.conv2.weight\"<FLOAT,[128,128,3,3]>{TorchTensor(...)},\n",
              "                %\"rb2.time_proj.1.weight\"<FLOAT,[128,256]>{TorchTensor(...)},\n",
              "                %\"rb2.skip.weight\"<FLOAT,[128,64,1,1]>{TorchTensor(...)},\n",
              "                %\"down2.weight\"<FLOAT,[128,128,4,4]>{TorchTensor(...)},\n",
              "                %\"rb3.conv1.weight\"<FLOAT,[256,128,3,3]>{TorchTensor(...)},\n",
              "                %\"rb3.conv2.weight\"<FLOAT,[256,256,3,3]>{TorchTensor(...)},\n",
              "                %\"rb3.time_proj.1.weight\"<FLOAT,[256,256]>{TorchTensor(...)},\n",
              "                %\"rb3.skip.weight\"<FLOAT,[256,128,1,1]>{TorchTensor(...)},\n",
              "                %\"down3.weight\"<FLOAT,[256,256,4,4]>{TorchTensor(...)},\n",
              "                %\"mid1.conv1.weight\"<FLOAT,[256,256,3,3]>{TorchTensor(...)},\n",
              "                %\"mid1.conv2.weight\"<FLOAT,[256,256,3,3]>{TorchTensor(...)},\n",
              "                %\"mid1.time_proj.1.weight\"<FLOAT,[256,256]>{TorchTensor(...)},\n",
              "                %\"mid2.conv1.weight\"<FLOAT,[256,256,3,3]>{TorchTensor(...)},\n",
              "                %\"mid2.conv2.weight\"<FLOAT,[256,256,3,3]>{TorchTensor(...)},\n",
              "                %\"mid2.time_proj.1.weight\"<FLOAT,[256,256]>{TorchTensor(...)},\n",
              "                %\"up3.weight\"<FLOAT,[256,256,4,4]>{TorchTensor(...)},\n",
              "                %\"urb3.conv1.weight\"<FLOAT,[128,512,3,3]>{TorchTensor(...)},\n",
              "                %\"urb3.conv2.weight\"<FLOAT,[128,128,3,3]>{TorchTensor(...)},\n",
              "                %\"urb3.time_proj.1.weight\"<FLOAT,[128,256]>{TorchTensor(...)},\n",
              "                %\"urb3.skip.weight\"<FLOAT,[128,512,1,1]>{TorchTensor(...)},\n",
              "                %\"up2.weight\"<FLOAT,[128,128,4,4]>{TorchTensor(...)},\n",
              "                %\"urb2.conv1.weight\"<FLOAT,[64,256,3,3]>{TorchTensor(...)},\n",
              "                %\"urb2.conv2.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
              "                %\"urb2.time_proj.1.weight\"<FLOAT,[64,256]>{TorchTensor(...)},\n",
              "                %\"urb2.skip.weight\"<FLOAT,[64,256,1,1]>{TorchTensor(...)},\n",
              "                %\"up1.weight\"<FLOAT,[64,64,4,4]>{TorchTensor(...)},\n",
              "                %\"urb1.conv1.weight\"<FLOAT,[64,128,3,3]>{TorchTensor(...)},\n",
              "                %\"urb1.conv2.weight\"<FLOAT,[64,64,3,3]>{TorchTensor(...)},\n",
              "                %\"urb1.time_proj.1.weight\"<FLOAT,[64,256]>{TorchTensor(...)},\n",
              "                %\"urb1.skip.weight\"<FLOAT,[64,128,1,1]>{TorchTensor(...)},\n",
              "                %\"conv_out.2.weight\"<FLOAT,[3,64,3,3]>{TorchTensor(...)},\n",
              "                %\"unsqueeze_1\"<FLOAT,[1,128]>{Tensor(...)},\n",
              "                %\"val_25\"<INT64,[3]>{Tensor<INT64,[3]>(array([ 0,  8, -1]), name='val_25')},\n",
              "                %\"val_29\"<FLOAT,[8]>{Tensor<FLOAT,[8]>(array([1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), name='val_29')},\n",
              "                %\"val_32\"<FLOAT,[8]>{Tensor<FLOAT,[8]>(array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), name='val_32')},\n",
              "                %\"val_42\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_44\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_78\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_80\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_101\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_103\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_135\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_137\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_158\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_160\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_192\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_194\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_215\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_217\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_249\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_251\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_272\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_274\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_306\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_308\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_329\"<FLOAT,[512,1,1]>{Tensor(...)},\n",
              "                %\"val_331\"<FLOAT,[512,1,1]>{Tensor(...)},\n",
              "                %\"val_363\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_365\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_386\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_388\"<FLOAT,[256,1,1]>{Tensor(...)},\n",
              "                %\"val_420\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_422\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_443\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_445\"<FLOAT,[128,1,1]>{Tensor(...)},\n",
              "                %\"val_477\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_479\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_500\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_502\"<FLOAT,[64,1,1]>{Tensor(...)},\n",
              "                %\"val_18\"<INT64,[1]>{TensorProtoTensor<INT64,[1]>(array([1]), name='val_18')},\n",
              "                %\"val_504\"<INT64,[2]>{Tensor<INT64,[2]>(array([2, 3]), name='val_504')}\n",
              "            ),\n",
              "        ) {\n",
              "              0 |  # node__to_copy\n",
              "                   %\"_to_copy\"<FLOAT,[s13]> ⬅️ ::Cast(%\"t\") {to=1}\n",
              "              1 |  # node_unsqueeze\n",
              "                   %\"unsqueeze\"<FLOAT,[s13,1]> ⬅️ ::Unsqueeze(%\"_to_copy\", %\"val_18\"{[1]})\n",
              "              2 |  # node_mul_4\n",
              "                   %\"mul_4\"<FLOAT,[s13,128]> ⬅️ ::Mul(%\"unsqueeze\", %\"unsqueeze_1\"{...})\n",
              "              3 |  # node_sin\n",
              "                   %\"sin\"<FLOAT,[s13,128]> ⬅️ ::Sin(%\"mul_4\")\n",
              "              4 |  # node_cos\n",
              "                   %\"cos\"<FLOAT,[s13,128]> ⬅️ ::Cos(%\"mul_4\")\n",
              "              5 |  # node_cat\n",
              "                   %\"cat\"<FLOAT,[s13,256]> ⬅️ ::Concat(%\"sin\", %\"cos\") {axis=-1}\n",
              "              6 |  # node_linear\n",
              "                   %\"linear\"<FLOAT,[s13,256]> ⬅️ ::Gemm(%\"cat\", %\"time_mlp.0.weight\"{...}, %\"time_mlp.0.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "              7 |  # node_Sigmoid_20\n",
              "                   %\"val_20\"<FLOAT,[s13,256]> ⬅️ ::Sigmoid(%\"linear\")\n",
              "              8 |  # node_silu\n",
              "                   %\"silu\"<FLOAT,[s13,256]> ⬅️ ::Mul(%\"linear\", %\"val_20\")\n",
              "              9 |  # node_linear_1\n",
              "                   %\"linear_1\"<FLOAT,[s13,256]> ⬅️ ::Gemm(%\"silu\", %\"time_mlp.2.weight\"{...}, %\"time_mlp.2.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "             10 |  # node_conv2d\n",
              "                   %\"conv2d\"<FLOAT,[s13,64,64,64]> ⬅️ ::Conv(%\"x\", %\"conv_in.weight\"{...}, %\"conv_in.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             11 |  # node_Reshape_26\n",
              "                   %\"val_26\"<FLOAT,[unk__2,8,32768]> ⬅️ ::Reshape(%\"conv2d\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             12 |  # node_InstanceNormalization_33\n",
              "                   %\"val_33\"<FLOAT,[unk__2,8,32768]> ⬅️ ::InstanceNormalization(%\"val_26\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             13 |  # node_Shape_34\n",
              "                   %\"val_34\"<INT64,[4]> ⬅️ ::Shape(%\"conv2d\") {start=0}\n",
              "             14 |  # node_Reshape_35\n",
              "                   %\"val_35\"<FLOAT,[unk__7,unk__8,unk__9,unk__10]> ⬅️ ::Reshape(%\"val_33\", %\"val_34\") {allowzero=0}\n",
              "             15 |  # node_Mul_43\n",
              "                   %\"val_43\"<FLOAT,[unk__7,64,unk__9,unk__10]> ⬅️ ::Mul(%\"val_35\", %\"val_42\"{...})\n",
              "             16 |  # node_group_norm\n",
              "                   %\"group_norm\"<FLOAT,[s13,64,64,64]> ⬅️ ::Add(%\"val_43\", %\"val_44\"{...})\n",
              "             17 |  # node_Sigmoid_45\n",
              "                   %\"val_45\"<FLOAT,[s13,64,64,64]> ⬅️ ::Sigmoid(%\"group_norm\")\n",
              "             18 |  # node_silu_1\n",
              "                   %\"silu_1\"<FLOAT,[s13,64,64,64]> ⬅️ ::Mul(%\"group_norm\", %\"val_45\")\n",
              "             19 |  # node_conv2d_1\n",
              "                   %\"conv2d_1\"<FLOAT,[s13,64,64,64]> ⬅️ ::Conv(%\"silu_1\", %\"rb1.conv1.weight\"{...}, %\"rb1.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             20 |  # node_Sigmoid_46\n",
              "                   %\"val_46\"<FLOAT,[s13,256]> ⬅️ ::Sigmoid(%\"linear_1\")\n",
              "             21 |  # node_silu_2\n",
              "                   %\"silu_2\"<FLOAT,[s13,256]> ⬅️ ::Mul(%\"linear_1\", %\"val_46\")\n",
              "             22 |  # node_linear_2\n",
              "                   %\"linear_2\"<FLOAT,[s13,64]> ⬅️ ::Gemm(%\"silu_2\", %\"rb1.time_proj.1.weight\"{...}, %\"rb1.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "             23 |  # node_Unsqueeze_101\n",
              "                   %\"unsqueeze_3\"<FLOAT,[s13,64,1,1]> ⬅️ ::Unsqueeze(%\"linear_2\", %\"val_504\"{[2, 3]})\n",
              "             24 |  # node_add_66\n",
              "                   %\"add_66\"<FLOAT,[s13,64,64,64]> ⬅️ ::Add(%\"conv2d_1\", %\"unsqueeze_3\")\n",
              "             25 |  # node_Reshape_63\n",
              "                   %\"val_63\"<FLOAT,[unk__14,8,32768]> ⬅️ ::Reshape(%\"add_66\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             26 |  # node_InstanceNormalization_70\n",
              "                   %\"val_70\"<FLOAT,[unk__14,8,32768]> ⬅️ ::InstanceNormalization(%\"val_63\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             27 |  # node_Shape_71\n",
              "                   %\"val_71\"<INT64,[4]> ⬅️ ::Shape(%\"add_66\") {start=0}\n",
              "             28 |  # node_Reshape_72\n",
              "                   %\"val_72\"<FLOAT,[unk__19,unk__20,unk__21,unk__22]> ⬅️ ::Reshape(%\"val_70\", %\"val_71\") {allowzero=0}\n",
              "             29 |  # node_Mul_79\n",
              "                   %\"val_79\"<FLOAT,[unk__19,64,unk__21,unk__22]> ⬅️ ::Mul(%\"val_72\", %\"val_78\"{...})\n",
              "             30 |  # node_group_norm_1\n",
              "                   %\"group_norm_1\"<FLOAT,[1,64,64,64]> ⬅️ ::Add(%\"val_79\", %\"val_80\"{...})\n",
              "             31 |  # node_Sigmoid_81\n",
              "                   %\"val_81\"<FLOAT,[1,64,64,64]> ⬅️ ::Sigmoid(%\"group_norm_1\")\n",
              "             32 |  # node_silu_3\n",
              "                   %\"silu_3\"<FLOAT,[1,64,64,64]> ⬅️ ::Mul(%\"group_norm_1\", %\"val_81\")\n",
              "             33 |  # node_conv2d_2\n",
              "                   %\"conv2d_2\"<FLOAT,[1,64,64,64]> ⬅️ ::Conv(%\"silu_3\", %\"rb1.conv2.weight\"{...}, %\"rb1.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             34 |  # node_add_72\n",
              "                   %\"add_72\"<FLOAT,[s13,64,64,64]> ⬅️ ::Add(%\"conv2d_2\", %\"conv2d\")\n",
              "             35 |  # node_conv2d_3\n",
              "                   %\"conv2d_3\"<FLOAT,[s13,64,32,32]> ⬅️ ::Conv(%\"add_72\", %\"down1.weight\"{...}, %\"down1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             36 |  # node_Reshape_86\n",
              "                   %\"val_86\"<FLOAT,[unk__24,8,8192]> ⬅️ ::Reshape(%\"conv2d_3\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             37 |  # node_InstanceNormalization_93\n",
              "                   %\"val_93\"<FLOAT,[unk__24,8,8192]> ⬅️ ::InstanceNormalization(%\"val_86\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             38 |  # node_Shape_94\n",
              "                   %\"val_94\"<INT64,[4]> ⬅️ ::Shape(%\"conv2d_3\") {start=0}\n",
              "             39 |  # node_Reshape_95\n",
              "                   %\"val_95\"<FLOAT,[unk__29,unk__30,unk__31,unk__32]> ⬅️ ::Reshape(%\"val_93\", %\"val_94\") {allowzero=0}\n",
              "             40 |  # node_Mul_102\n",
              "                   %\"val_102\"<FLOAT,[unk__29,64,unk__31,unk__32]> ⬅️ ::Mul(%\"val_95\", %\"val_101\"{...})\n",
              "             41 |  # node_group_norm_2\n",
              "                   %\"group_norm_2\"<FLOAT,[s13,64,32,32]> ⬅️ ::Add(%\"val_102\", %\"val_103\"{...})\n",
              "             42 |  # node_Sigmoid_104\n",
              "                   %\"val_104\"<FLOAT,[s13,64,32,32]> ⬅️ ::Sigmoid(%\"group_norm_2\")\n",
              "             43 |  # node_silu_4\n",
              "                   %\"silu_4\"<FLOAT,[s13,64,32,32]> ⬅️ ::Mul(%\"group_norm_2\", %\"val_104\")\n",
              "             44 |  # node_conv2d_4\n",
              "                   %\"conv2d_4\"<FLOAT,[s13,128,32,32]> ⬅️ ::Conv(%\"silu_4\", %\"rb2.conv1.weight\"{...}, %\"rb2.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             45 |  # node_linear_3\n",
              "                   %\"linear_3\"<FLOAT,[s13,128]> ⬅️ ::Gemm(%\"silu_2\", %\"rb2.time_proj.1.weight\"{...}, %\"rb2.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "             46 |  # node_Unsqueeze_104\n",
              "                   %\"unsqueeze_5\"<FLOAT,[s13,128,1,1]> ⬅️ ::Unsqueeze(%\"linear_3\", %\"val_504\"{[2, 3]})\n",
              "             47 |  # node_add_116\n",
              "                   %\"add_116\"<FLOAT,[s13,128,32,32]> ⬅️ ::Add(%\"conv2d_4\", %\"unsqueeze_5\")\n",
              "             48 |  # node_Reshape_120\n",
              "                   %\"val_120\"<FLOAT,[unk__36,8,16384]> ⬅️ ::Reshape(%\"add_116\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             49 |  # node_InstanceNormalization_127\n",
              "                   %\"val_127\"<FLOAT,[unk__36,8,16384]> ⬅️ ::InstanceNormalization(%\"val_120\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             50 |  # node_Shape_128\n",
              "                   %\"val_128\"<INT64,[4]> ⬅️ ::Shape(%\"add_116\") {start=0}\n",
              "             51 |  # node_Reshape_129\n",
              "                   %\"val_129\"<FLOAT,[unk__41,unk__42,unk__43,unk__44]> ⬅️ ::Reshape(%\"val_127\", %\"val_128\") {allowzero=0}\n",
              "             52 |  # node_Mul_136\n",
              "                   %\"val_136\"<FLOAT,[unk__41,128,unk__43,unk__44]> ⬅️ ::Mul(%\"val_129\", %\"val_135\"{...})\n",
              "             53 |  # node_group_norm_3\n",
              "                   %\"group_norm_3\"<FLOAT,[1,128,32,32]> ⬅️ ::Add(%\"val_136\", %\"val_137\"{...})\n",
              "             54 |  # node_Sigmoid_138\n",
              "                   %\"val_138\"<FLOAT,[1,128,32,32]> ⬅️ ::Sigmoid(%\"group_norm_3\")\n",
              "             55 |  # node_silu_6\n",
              "                   %\"silu_6\"<FLOAT,[1,128,32,32]> ⬅️ ::Mul(%\"group_norm_3\", %\"val_138\")\n",
              "             56 |  # node_conv2d_5\n",
              "                   %\"conv2d_5\"<FLOAT,[1,128,32,32]> ⬅️ ::Conv(%\"silu_6\", %\"rb2.conv2.weight\"{...}, %\"rb2.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             57 |  # node_conv2d_6\n",
              "                   %\"conv2d_6\"<FLOAT,[s13,128,32,32]> ⬅️ ::Conv(%\"conv2d_3\", %\"rb2.skip.weight\"{...}, %\"rb2.skip.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             58 |  # node_add_127\n",
              "                   %\"add_127\"<FLOAT,[s13,128,32,32]> ⬅️ ::Add(%\"conv2d_5\", %\"conv2d_6\")\n",
              "             59 |  # node_conv2d_7\n",
              "                   %\"conv2d_7\"<FLOAT,[s13,128,16,16]> ⬅️ ::Conv(%\"add_127\", %\"down2.weight\"{...}, %\"down2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             60 |  # node_Reshape_143\n",
              "                   %\"val_143\"<FLOAT,[unk__46,8,4096]> ⬅️ ::Reshape(%\"conv2d_7\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             61 |  # node_InstanceNormalization_150\n",
              "                   %\"val_150\"<FLOAT,[unk__46,8,4096]> ⬅️ ::InstanceNormalization(%\"val_143\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             62 |  # node_Shape_151\n",
              "                   %\"val_151\"<INT64,[4]> ⬅️ ::Shape(%\"conv2d_7\") {start=0}\n",
              "             63 |  # node_Reshape_152\n",
              "                   %\"val_152\"<FLOAT,[unk__51,unk__52,unk__53,unk__54]> ⬅️ ::Reshape(%\"val_150\", %\"val_151\") {allowzero=0}\n",
              "             64 |  # node_Mul_159\n",
              "                   %\"val_159\"<FLOAT,[unk__51,128,unk__53,unk__54]> ⬅️ ::Mul(%\"val_152\", %\"val_158\"{...})\n",
              "             65 |  # node_group_norm_4\n",
              "                   %\"group_norm_4\"<FLOAT,[s13,128,16,16]> ⬅️ ::Add(%\"val_159\", %\"val_160\"{...})\n",
              "             66 |  # node_Sigmoid_161\n",
              "                   %\"val_161\"<FLOAT,[s13,128,16,16]> ⬅️ ::Sigmoid(%\"group_norm_4\")\n",
              "             67 |  # node_silu_7\n",
              "                   %\"silu_7\"<FLOAT,[s13,128,16,16]> ⬅️ ::Mul(%\"group_norm_4\", %\"val_161\")\n",
              "             68 |  # node_conv2d_8\n",
              "                   %\"conv2d_8\"<FLOAT,[s13,256,16,16]> ⬅️ ::Conv(%\"silu_7\", %\"rb3.conv1.weight\"{...}, %\"rb3.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             69 |  # node_linear_4\n",
              "                   %\"linear_4\"<FLOAT,[s13,256]> ⬅️ ::Gemm(%\"silu_2\", %\"rb3.time_proj.1.weight\"{...}, %\"rb3.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "             70 |  # node_Unsqueeze_107\n",
              "                   %\"unsqueeze_7\"<FLOAT,[s13,256,1,1]> ⬅️ ::Unsqueeze(%\"linear_4\", %\"val_504\"{[2, 3]})\n",
              "             71 |  # node_add_171\n",
              "                   %\"add_171\"<FLOAT,[s13,256,16,16]> ⬅️ ::Add(%\"conv2d_8\", %\"unsqueeze_7\")\n",
              "             72 |  # node_Reshape_177\n",
              "                   %\"val_177\"<FLOAT,[unk__58,8,8192]> ⬅️ ::Reshape(%\"add_171\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             73 |  # node_InstanceNormalization_184\n",
              "                   %\"val_184\"<FLOAT,[unk__58,8,8192]> ⬅️ ::InstanceNormalization(%\"val_177\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             74 |  # node_Shape_185\n",
              "                   %\"val_185\"<INT64,[4]> ⬅️ ::Shape(%\"add_171\") {start=0}\n",
              "             75 |  # node_Reshape_186\n",
              "                   %\"val_186\"<FLOAT,[unk__63,unk__64,unk__65,unk__66]> ⬅️ ::Reshape(%\"val_184\", %\"val_185\") {allowzero=0}\n",
              "             76 |  # node_Mul_193\n",
              "                   %\"val_193\"<FLOAT,[unk__63,256,unk__65,unk__66]> ⬅️ ::Mul(%\"val_186\", %\"val_192\"{...})\n",
              "             77 |  # node_group_norm_5\n",
              "                   %\"group_norm_5\"<FLOAT,[1,256,16,16]> ⬅️ ::Add(%\"val_193\", %\"val_194\"{...})\n",
              "             78 |  # node_Sigmoid_195\n",
              "                   %\"val_195\"<FLOAT,[1,256,16,16]> ⬅️ ::Sigmoid(%\"group_norm_5\")\n",
              "             79 |  # node_silu_9\n",
              "                   %\"silu_9\"<FLOAT,[1,256,16,16]> ⬅️ ::Mul(%\"group_norm_5\", %\"val_195\")\n",
              "             80 |  # node_conv2d_9\n",
              "                   %\"conv2d_9\"<FLOAT,[1,256,16,16]> ⬅️ ::Conv(%\"silu_9\", %\"rb3.conv2.weight\"{...}, %\"rb3.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             81 |  # node_conv2d_10\n",
              "                   %\"conv2d_10\"<FLOAT,[s13,256,16,16]> ⬅️ ::Conv(%\"conv2d_7\", %\"rb3.skip.weight\"{...}, %\"rb3.skip.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             82 |  # node_add_182\n",
              "                   %\"add_182\"<FLOAT,[s13,256,16,16]> ⬅️ ::Add(%\"conv2d_9\", %\"conv2d_10\")\n",
              "             83 |  # node_conv2d_11\n",
              "                   %\"conv2d_11\"<FLOAT,[s13,256,8,8]> ⬅️ ::Conv(%\"add_182\", %\"down3.weight\"{...}, %\"down3.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
              "             84 |  # node_Reshape_200\n",
              "                   %\"val_200\"<FLOAT,[unk__68,8,2048]> ⬅️ ::Reshape(%\"conv2d_11\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             85 |  # node_InstanceNormalization_207\n",
              "                   %\"val_207\"<FLOAT,[unk__68,8,2048]> ⬅️ ::InstanceNormalization(%\"val_200\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             86 |  # node_Shape_208\n",
              "                   %\"val_208\"<INT64,[4]> ⬅️ ::Shape(%\"conv2d_11\") {start=0}\n",
              "             87 |  # node_Reshape_209\n",
              "                   %\"val_209\"<FLOAT,[unk__73,unk__74,unk__75,unk__76]> ⬅️ ::Reshape(%\"val_207\", %\"val_208\") {allowzero=0}\n",
              "             88 |  # node_Mul_216\n",
              "                   %\"val_216\"<FLOAT,[unk__73,256,unk__75,unk__76]> ⬅️ ::Mul(%\"val_209\", %\"val_215\"{...})\n",
              "             89 |  # node_group_norm_6\n",
              "                   %\"group_norm_6\"<FLOAT,[s13,256,8,8]> ⬅️ ::Add(%\"val_216\", %\"val_217\"{...})\n",
              "             90 |  # node_Sigmoid_218\n",
              "                   %\"val_218\"<FLOAT,[s13,256,8,8]> ⬅️ ::Sigmoid(%\"group_norm_6\")\n",
              "             91 |  # node_silu_10\n",
              "                   %\"silu_10\"<FLOAT,[s13,256,8,8]> ⬅️ ::Mul(%\"group_norm_6\", %\"val_218\")\n",
              "             92 |  # node_conv2d_12\n",
              "                   %\"conv2d_12\"<FLOAT,[s13,256,8,8]> ⬅️ ::Conv(%\"silu_10\", %\"mid1.conv1.weight\"{...}, %\"mid1.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "             93 |  # node_linear_5\n",
              "                   %\"linear_5\"<FLOAT,[s13,256]> ⬅️ ::Gemm(%\"silu_2\", %\"mid1.time_proj.1.weight\"{...}, %\"mid1.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "             94 |  # node_Unsqueeze_110\n",
              "                   %\"unsqueeze_9\"<FLOAT,[s13,256,1,1]> ⬅️ ::Unsqueeze(%\"linear_5\", %\"val_504\"{[2, 3]})\n",
              "             95 |  # node_add_226\n",
              "                   %\"add_226\"<FLOAT,[s13,256,8,8]> ⬅️ ::Add(%\"conv2d_12\", %\"unsqueeze_9\")\n",
              "             96 |  # node_Reshape_234\n",
              "                   %\"val_234\"<FLOAT,[unk__80,8,2048]> ⬅️ ::Reshape(%\"add_226\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "             97 |  # node_InstanceNormalization_241\n",
              "                   %\"val_241\"<FLOAT,[unk__80,8,2048]> ⬅️ ::InstanceNormalization(%\"val_234\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "             98 |  # node_Shape_242\n",
              "                   %\"val_242\"<INT64,[4]> ⬅️ ::Shape(%\"add_226\") {start=0}\n",
              "             99 |  # node_Reshape_243\n",
              "                   %\"val_243\"<FLOAT,[unk__85,unk__86,unk__87,unk__88]> ⬅️ ::Reshape(%\"val_241\", %\"val_242\") {allowzero=0}\n",
              "            100 |  # node_Mul_250\n",
              "                   %\"val_250\"<FLOAT,[unk__85,256,unk__87,unk__88]> ⬅️ ::Mul(%\"val_243\", %\"val_249\"{...})\n",
              "            101 |  # node_group_norm_7\n",
              "                   %\"group_norm_7\"<FLOAT,[1,256,8,8]> ⬅️ ::Add(%\"val_250\", %\"val_251\"{...})\n",
              "            102 |  # node_Sigmoid_252\n",
              "                   %\"val_252\"<FLOAT,[1,256,8,8]> ⬅️ ::Sigmoid(%\"group_norm_7\")\n",
              "            103 |  # node_silu_12\n",
              "                   %\"silu_12\"<FLOAT,[1,256,8,8]> ⬅️ ::Mul(%\"group_norm_7\", %\"val_252\")\n",
              "            104 |  # node_conv2d_13\n",
              "                   %\"conv2d_13\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"silu_12\", %\"mid1.conv2.weight\"{...}, %\"mid1.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            105 |  # node_add_232\n",
              "                   %\"add_232\"<FLOAT,[s13,256,8,8]> ⬅️ ::Add(%\"conv2d_13\", %\"conv2d_11\")\n",
              "            106 |  # node_Reshape_257\n",
              "                   %\"val_257\"<FLOAT,[unk__90,8,2048]> ⬅️ ::Reshape(%\"add_232\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            107 |  # node_InstanceNormalization_264\n",
              "                   %\"val_264\"<FLOAT,[unk__90,8,2048]> ⬅️ ::InstanceNormalization(%\"val_257\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            108 |  # node_Shape_265\n",
              "                   %\"val_265\"<INT64,[4]> ⬅️ ::Shape(%\"add_232\") {start=0}\n",
              "            109 |  # node_Reshape_266\n",
              "                   %\"val_266\"<FLOAT,[unk__95,unk__96,unk__97,unk__98]> ⬅️ ::Reshape(%\"val_264\", %\"val_265\") {allowzero=0}\n",
              "            110 |  # node_Mul_273\n",
              "                   %\"val_273\"<FLOAT,[unk__95,256,unk__97,unk__98]> ⬅️ ::Mul(%\"val_266\", %\"val_272\"{...})\n",
              "            111 |  # node_group_norm_8\n",
              "                   %\"group_norm_8\"<FLOAT,[s13,256,8,8]> ⬅️ ::Add(%\"val_273\", %\"val_274\"{...})\n",
              "            112 |  # node_Sigmoid_275\n",
              "                   %\"val_275\"<FLOAT,[s13,256,8,8]> ⬅️ ::Sigmoid(%\"group_norm_8\")\n",
              "            113 |  # node_silu_13\n",
              "                   %\"silu_13\"<FLOAT,[s13,256,8,8]> ⬅️ ::Mul(%\"group_norm_8\", %\"val_275\")\n",
              "            114 |  # node_conv2d_14\n",
              "                   %\"conv2d_14\"<FLOAT,[s13,256,8,8]> ⬅️ ::Conv(%\"silu_13\", %\"mid2.conv1.weight\"{...}, %\"mid2.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            115 |  # node_linear_6\n",
              "                   %\"linear_6\"<FLOAT,[s13,256]> ⬅️ ::Gemm(%\"silu_2\", %\"mid2.time_proj.1.weight\"{...}, %\"mid2.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            116 |  # node_Unsqueeze_113\n",
              "                   %\"unsqueeze_11\"<FLOAT,[s13,256,1,1]> ⬅️ ::Unsqueeze(%\"linear_6\", %\"val_504\"{[2, 3]})\n",
              "            117 |  # node_add_271\n",
              "                   %\"add_271\"<FLOAT,[s13,256,8,8]> ⬅️ ::Add(%\"conv2d_14\", %\"unsqueeze_11\")\n",
              "            118 |  # node_Reshape_291\n",
              "                   %\"val_291\"<FLOAT,[unk__102,8,2048]> ⬅️ ::Reshape(%\"add_271\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            119 |  # node_InstanceNormalization_298\n",
              "                   %\"val_298\"<FLOAT,[unk__102,8,2048]> ⬅️ ::InstanceNormalization(%\"val_291\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            120 |  # node_Shape_299\n",
              "                   %\"val_299\"<INT64,[4]> ⬅️ ::Shape(%\"add_271\") {start=0}\n",
              "            121 |  # node_Reshape_300\n",
              "                   %\"val_300\"<FLOAT,[unk__107,unk__108,unk__109,unk__110]> ⬅️ ::Reshape(%\"val_298\", %\"val_299\") {allowzero=0}\n",
              "            122 |  # node_Mul_307\n",
              "                   %\"val_307\"<FLOAT,[unk__107,256,unk__109,unk__110]> ⬅️ ::Mul(%\"val_300\", %\"val_306\"{...})\n",
              "            123 |  # node_group_norm_9\n",
              "                   %\"group_norm_9\"<FLOAT,[1,256,8,8]> ⬅️ ::Add(%\"val_307\", %\"val_308\"{...})\n",
              "            124 |  # node_Sigmoid_309\n",
              "                   %\"val_309\"<FLOAT,[1,256,8,8]> ⬅️ ::Sigmoid(%\"group_norm_9\")\n",
              "            125 |  # node_silu_15\n",
              "                   %\"silu_15\"<FLOAT,[1,256,8,8]> ⬅️ ::Mul(%\"group_norm_9\", %\"val_309\")\n",
              "            126 |  # node_conv2d_15\n",
              "                   %\"conv2d_15\"<FLOAT,[1,256,8,8]> ⬅️ ::Conv(%\"silu_15\", %\"mid2.conv2.weight\"{...}, %\"mid2.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            127 |  # node_add_277\n",
              "                   %\"add_277\"<FLOAT,[s13,256,8,8]> ⬅️ ::Add(%\"conv2d_15\", %\"add_232\")\n",
              "            128 |  # node_convolution\n",
              "                   %\"convolution\"<FLOAT,[s13,256,16,16]> ⬅️ ::ConvTranspose(%\"add_277\", %\"up3.weight\"{...}, %\"up3.bias\"{...}) {group=1, auto_pad='NOTSET', strides=(2, 2), pads=(1, 1, 1, 1), output_padding=(0, 0), dilations=(1, 1)}\n",
              "            129 |  # node_cat_1\n",
              "                   %\"cat_1\"<FLOAT,[s13,512,16,16]> ⬅️ ::Concat(%\"convolution\", %\"add_182\") {axis=1}\n",
              "            130 |  # node_Reshape_314\n",
              "                   %\"val_314\"<FLOAT,[unk__112,8,16384]> ⬅️ ::Reshape(%\"cat_1\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            131 |  # node_InstanceNormalization_321\n",
              "                   %\"val_321\"<FLOAT,[unk__112,8,16384]> ⬅️ ::InstanceNormalization(%\"val_314\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            132 |  # node_Shape_322\n",
              "                   %\"val_322\"<INT64,[4]> ⬅️ ::Shape(%\"cat_1\") {start=0}\n",
              "            133 |  # node_Reshape_323\n",
              "                   %\"val_323\"<FLOAT,[unk__117,unk__118,unk__119,unk__120]> ⬅️ ::Reshape(%\"val_321\", %\"val_322\") {allowzero=0}\n",
              "            134 |  # node_Mul_330\n",
              "                   %\"val_330\"<FLOAT,[unk__117,512,unk__119,unk__120]> ⬅️ ::Mul(%\"val_323\", %\"val_329\"{...})\n",
              "            135 |  # node_group_norm_10\n",
              "                   %\"group_norm_10\"<FLOAT,[s13,512,16,16]> ⬅️ ::Add(%\"val_330\", %\"val_331\"{...})\n",
              "            136 |  # node_Sigmoid_332\n",
              "                   %\"val_332\"<FLOAT,[s13,512,16,16]> ⬅️ ::Sigmoid(%\"group_norm_10\")\n",
              "            137 |  # node_silu_16\n",
              "                   %\"silu_16\"<FLOAT,[s13,512,16,16]> ⬅️ ::Mul(%\"group_norm_10\", %\"val_332\")\n",
              "            138 |  # node_conv2d_16\n",
              "                   %\"conv2d_16\"<FLOAT,[s13,128,16,16]> ⬅️ ::Conv(%\"silu_16\", %\"urb3.conv1.weight\"{...}, %\"urb3.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            139 |  # node_linear_7\n",
              "                   %\"linear_7\"<FLOAT,[s13,128]> ⬅️ ::Gemm(%\"silu_2\", %\"urb3.time_proj.1.weight\"{...}, %\"urb3.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            140 |  # node_Unsqueeze_118\n",
              "                   %\"unsqueeze_13\"<FLOAT,[s13,128,1,1]> ⬅️ ::Unsqueeze(%\"linear_7\", %\"val_504\"{[2, 3]})\n",
              "            141 |  # node_add_326\n",
              "                   %\"add_326\"<FLOAT,[s13,128,16,16]> ⬅️ ::Add(%\"conv2d_16\", %\"unsqueeze_13\")\n",
              "            142 |  # node_Reshape_348\n",
              "                   %\"val_348\"<FLOAT,[unk__124,8,4096]> ⬅️ ::Reshape(%\"add_326\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            143 |  # node_InstanceNormalization_355\n",
              "                   %\"val_355\"<FLOAT,[unk__124,8,4096]> ⬅️ ::InstanceNormalization(%\"val_348\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            144 |  # node_Shape_356\n",
              "                   %\"val_356\"<INT64,[4]> ⬅️ ::Shape(%\"add_326\") {start=0}\n",
              "            145 |  # node_Reshape_357\n",
              "                   %\"val_357\"<FLOAT,[unk__129,unk__130,unk__131,unk__132]> ⬅️ ::Reshape(%\"val_355\", %\"val_356\") {allowzero=0}\n",
              "            146 |  # node_Mul_364\n",
              "                   %\"val_364\"<FLOAT,[unk__129,128,unk__131,unk__132]> ⬅️ ::Mul(%\"val_357\", %\"val_363\"{...})\n",
              "            147 |  # node_group_norm_11\n",
              "                   %\"group_norm_11\"<FLOAT,[1,128,16,16]> ⬅️ ::Add(%\"val_364\", %\"val_365\"{...})\n",
              "            148 |  # node_Sigmoid_366\n",
              "                   %\"val_366\"<FLOAT,[1,128,16,16]> ⬅️ ::Sigmoid(%\"group_norm_11\")\n",
              "            149 |  # node_silu_18\n",
              "                   %\"silu_18\"<FLOAT,[1,128,16,16]> ⬅️ ::Mul(%\"group_norm_11\", %\"val_366\")\n",
              "            150 |  # node_conv2d_17\n",
              "                   %\"conv2d_17\"<FLOAT,[1,128,16,16]> ⬅️ ::Conv(%\"silu_18\", %\"urb3.conv2.weight\"{...}, %\"urb3.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            151 |  # node_conv2d_18\n",
              "                   %\"conv2d_18\"<FLOAT,[s13,128,16,16]> ⬅️ ::Conv(%\"cat_1\", %\"urb3.skip.weight\"{...}, %\"urb3.skip.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            152 |  # node_add_337\n",
              "                   %\"add_337\"<FLOAT,[s13,128,16,16]> ⬅️ ::Add(%\"conv2d_17\", %\"conv2d_18\")\n",
              "            153 |  # node_convolution_1\n",
              "                   %\"convolution_1\"<FLOAT,[s13,128,32,32]> ⬅️ ::ConvTranspose(%\"add_337\", %\"up2.weight\"{...}, %\"up2.bias\"{...}) {group=1, auto_pad='NOTSET', strides=(2, 2), pads=(1, 1, 1, 1), output_padding=(0, 0), dilations=(1, 1)}\n",
              "            154 |  # node_cat_2\n",
              "                   %\"cat_2\"<FLOAT,[s13,256,32,32]> ⬅️ ::Concat(%\"convolution_1\", %\"add_127\") {axis=1}\n",
              "            155 |  # node_Reshape_371\n",
              "                   %\"val_371\"<FLOAT,[unk__134,8,32768]> ⬅️ ::Reshape(%\"cat_2\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            156 |  # node_InstanceNormalization_378\n",
              "                   %\"val_378\"<FLOAT,[unk__134,8,32768]> ⬅️ ::InstanceNormalization(%\"val_371\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            157 |  # node_Shape_379\n",
              "                   %\"val_379\"<INT64,[4]> ⬅️ ::Shape(%\"cat_2\") {start=0}\n",
              "            158 |  # node_Reshape_380\n",
              "                   %\"val_380\"<FLOAT,[unk__139,unk__140,unk__141,unk__142]> ⬅️ ::Reshape(%\"val_378\", %\"val_379\") {allowzero=0}\n",
              "            159 |  # node_Mul_387\n",
              "                   %\"val_387\"<FLOAT,[unk__139,256,unk__141,unk__142]> ⬅️ ::Mul(%\"val_380\", %\"val_386\"{...})\n",
              "            160 |  # node_group_norm_12\n",
              "                   %\"group_norm_12\"<FLOAT,[s13,256,32,32]> ⬅️ ::Add(%\"val_387\", %\"val_388\"{...})\n",
              "            161 |  # node_Sigmoid_389\n",
              "                   %\"val_389\"<FLOAT,[s13,256,32,32]> ⬅️ ::Sigmoid(%\"group_norm_12\")\n",
              "            162 |  # node_silu_19\n",
              "                   %\"silu_19\"<FLOAT,[s13,256,32,32]> ⬅️ ::Mul(%\"group_norm_12\", %\"val_389\")\n",
              "            163 |  # node_conv2d_19\n",
              "                   %\"conv2d_19\"<FLOAT,[s13,64,32,32]> ⬅️ ::Conv(%\"silu_19\", %\"urb2.conv1.weight\"{...}, %\"urb2.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            164 |  # node_linear_8\n",
              "                   %\"linear_8\"<FLOAT,[s13,64]> ⬅️ ::Gemm(%\"silu_2\", %\"urb2.time_proj.1.weight\"{...}, %\"urb2.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            165 |  # node_Unsqueeze_121\n",
              "                   %\"unsqueeze_15\"<FLOAT,[s13,64,1,1]> ⬅️ ::Unsqueeze(%\"linear_8\", %\"val_504\"{[2, 3]})\n",
              "            166 |  # node_add_386\n",
              "                   %\"add_386\"<FLOAT,[s13,64,32,32]> ⬅️ ::Add(%\"conv2d_19\", %\"unsqueeze_15\")\n",
              "            167 |  # node_Reshape_405\n",
              "                   %\"val_405\"<FLOAT,[unk__146,8,8192]> ⬅️ ::Reshape(%\"add_386\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            168 |  # node_InstanceNormalization_412\n",
              "                   %\"val_412\"<FLOAT,[unk__146,8,8192]> ⬅️ ::InstanceNormalization(%\"val_405\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            169 |  # node_Shape_413\n",
              "                   %\"val_413\"<INT64,[4]> ⬅️ ::Shape(%\"add_386\") {start=0}\n",
              "            170 |  # node_Reshape_414\n",
              "                   %\"val_414\"<FLOAT,[unk__151,unk__152,unk__153,unk__154]> ⬅️ ::Reshape(%\"val_412\", %\"val_413\") {allowzero=0}\n",
              "            171 |  # node_Mul_421\n",
              "                   %\"val_421\"<FLOAT,[unk__151,64,unk__153,unk__154]> ⬅️ ::Mul(%\"val_414\", %\"val_420\"{...})\n",
              "            172 |  # node_group_norm_13\n",
              "                   %\"group_norm_13\"<FLOAT,[1,64,32,32]> ⬅️ ::Add(%\"val_421\", %\"val_422\"{...})\n",
              "            173 |  # node_Sigmoid_423\n",
              "                   %\"val_423\"<FLOAT,[1,64,32,32]> ⬅️ ::Sigmoid(%\"group_norm_13\")\n",
              "            174 |  # node_silu_21\n",
              "                   %\"silu_21\"<FLOAT,[1,64,32,32]> ⬅️ ::Mul(%\"group_norm_13\", %\"val_423\")\n",
              "            175 |  # node_conv2d_20\n",
              "                   %\"conv2d_20\"<FLOAT,[1,64,32,32]> ⬅️ ::Conv(%\"silu_21\", %\"urb2.conv2.weight\"{...}, %\"urb2.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            176 |  # node_conv2d_21\n",
              "                   %\"conv2d_21\"<FLOAT,[s13,64,32,32]> ⬅️ ::Conv(%\"cat_2\", %\"urb2.skip.weight\"{...}, %\"urb2.skip.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            177 |  # node_add_397\n",
              "                   %\"add_397\"<FLOAT,[s13,64,32,32]> ⬅️ ::Add(%\"conv2d_20\", %\"conv2d_21\")\n",
              "            178 |  # node_convolution_2\n",
              "                   %\"convolution_2\"<FLOAT,[s13,64,64,64]> ⬅️ ::ConvTranspose(%\"add_397\", %\"up1.weight\"{...}, %\"up1.bias\"{...}) {group=1, auto_pad='NOTSET', strides=(2, 2), pads=(1, 1, 1, 1), output_padding=(0, 0), dilations=(1, 1)}\n",
              "            179 |  # node_cat_3\n",
              "                   %\"cat_3\"<FLOAT,[s13,128,64,64]> ⬅️ ::Concat(%\"convolution_2\", %\"add_72\") {axis=1}\n",
              "            180 |  # node_Reshape_428\n",
              "                   %\"val_428\"<FLOAT,[unk__156,8,65536]> ⬅️ ::Reshape(%\"cat_3\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            181 |  # node_InstanceNormalization_435\n",
              "                   %\"val_435\"<FLOAT,[unk__156,8,65536]> ⬅️ ::InstanceNormalization(%\"val_428\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            182 |  # node_Shape_436\n",
              "                   %\"val_436\"<INT64,[4]> ⬅️ ::Shape(%\"cat_3\") {start=0}\n",
              "            183 |  # node_Reshape_437\n",
              "                   %\"val_437\"<FLOAT,[unk__161,unk__162,unk__163,unk__164]> ⬅️ ::Reshape(%\"val_435\", %\"val_436\") {allowzero=0}\n",
              "            184 |  # node_Mul_444\n",
              "                   %\"val_444\"<FLOAT,[unk__161,128,unk__163,unk__164]> ⬅️ ::Mul(%\"val_437\", %\"val_443\"{...})\n",
              "            185 |  # node_group_norm_14\n",
              "                   %\"group_norm_14\"<FLOAT,[s13,128,64,64]> ⬅️ ::Add(%\"val_444\", %\"val_445\"{...})\n",
              "            186 |  # node_Sigmoid_446\n",
              "                   %\"val_446\"<FLOAT,[s13,128,64,64]> ⬅️ ::Sigmoid(%\"group_norm_14\")\n",
              "            187 |  # node_silu_22\n",
              "                   %\"silu_22\"<FLOAT,[s13,128,64,64]> ⬅️ ::Mul(%\"group_norm_14\", %\"val_446\")\n",
              "            188 |  # node_conv2d_22\n",
              "                   %\"conv2d_22\"<FLOAT,[s13,64,64,64]> ⬅️ ::Conv(%\"silu_22\", %\"urb1.conv1.weight\"{...}, %\"urb1.conv1.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            189 |  # node_linear_9\n",
              "                   %\"linear_9\"<FLOAT,[s13,64]> ⬅️ ::Gemm(%\"silu_2\", %\"urb1.time_proj.1.weight\"{...}, %\"urb1.time_proj.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            190 |  # node_Unsqueeze_124\n",
              "                   %\"unsqueeze_17\"<FLOAT,[s13,64,1,1]> ⬅️ ::Unsqueeze(%\"linear_9\", %\"val_504\"{[2, 3]})\n",
              "            191 |  # node_add_446\n",
              "                   %\"add_446\"<FLOAT,[s13,64,64,64]> ⬅️ ::Add(%\"conv2d_22\", %\"unsqueeze_17\")\n",
              "            192 |  # node_Reshape_462\n",
              "                   %\"val_462\"<FLOAT,[unk__168,8,32768]> ⬅️ ::Reshape(%\"add_446\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            193 |  # node_InstanceNormalization_469\n",
              "                   %\"val_469\"<FLOAT,[unk__168,8,32768]> ⬅️ ::InstanceNormalization(%\"val_462\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            194 |  # node_Shape_470\n",
              "                   %\"val_470\"<INT64,[4]> ⬅️ ::Shape(%\"add_446\") {start=0}\n",
              "            195 |  # node_Reshape_471\n",
              "                   %\"val_471\"<FLOAT,[unk__173,unk__174,unk__175,unk__176]> ⬅️ ::Reshape(%\"val_469\", %\"val_470\") {allowzero=0}\n",
              "            196 |  # node_Mul_478\n",
              "                   %\"val_478\"<FLOAT,[unk__173,64,unk__175,unk__176]> ⬅️ ::Mul(%\"val_471\", %\"val_477\"{...})\n",
              "            197 |  # node_group_norm_15\n",
              "                   %\"group_norm_15\"<FLOAT,[1,64,64,64]> ⬅️ ::Add(%\"val_478\", %\"val_479\"{...})\n",
              "            198 |  # node_Sigmoid_480\n",
              "                   %\"val_480\"<FLOAT,[1,64,64,64]> ⬅️ ::Sigmoid(%\"group_norm_15\")\n",
              "            199 |  # node_silu_24\n",
              "                   %\"silu_24\"<FLOAT,[1,64,64,64]> ⬅️ ::Mul(%\"group_norm_15\", %\"val_480\")\n",
              "            200 |  # node_conv2d_23\n",
              "                   %\"conv2d_23\"<FLOAT,[1,64,64,64]> ⬅️ ::Conv(%\"silu_24\", %\"urb1.conv2.weight\"{...}, %\"urb1.conv2.bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            201 |  # node_conv2d_24\n",
              "                   %\"conv2d_24\"<FLOAT,[s13,64,64,64]> ⬅️ ::Conv(%\"cat_3\", %\"urb1.skip.weight\"{...}, %\"urb1.skip.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            202 |  # node_add_457\n",
              "                   %\"add_457\"<FLOAT,[s13,64,64,64]> ⬅️ ::Add(%\"conv2d_23\", %\"conv2d_24\")\n",
              "            203 |  # node_Reshape_485\n",
              "                   %\"val_485\"<FLOAT,[unk__178,8,32768]> ⬅️ ::Reshape(%\"add_457\", %\"val_25\"{[0, 8, -1]}) {allowzero=0}\n",
              "            204 |  # node_InstanceNormalization_492\n",
              "                   %\"val_492\"<FLOAT,[unk__178,8,32768]> ⬅️ ::InstanceNormalization(%\"val_485\", %\"val_29\"{[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, %\"val_32\"{[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}) {epsilon=9.999999747378752e-06}\n",
              "            205 |  # node_Shape_493\n",
              "                   %\"val_493\"<INT64,[4]> ⬅️ ::Shape(%\"add_457\") {start=0}\n",
              "            206 |  # node_Reshape_494\n",
              "                   %\"val_494\"<FLOAT,[unk__183,unk__184,unk__185,unk__186]> ⬅️ ::Reshape(%\"val_492\", %\"val_493\") {allowzero=0}\n",
              "            207 |  # node_Mul_501\n",
              "                   %\"val_501\"<FLOAT,[unk__183,64,unk__185,unk__186]> ⬅️ ::Mul(%\"val_494\", %\"val_500\"{...})\n",
              "            208 |  # node_group_norm_16\n",
              "                   %\"group_norm_16\"<FLOAT,[s13,64,64,64]> ⬅️ ::Add(%\"val_501\", %\"val_502\"{...})\n",
              "            209 |  # node_Sigmoid_503\n",
              "                   %\"val_503\"<FLOAT,[s13,64,64,64]> ⬅️ ::Sigmoid(%\"group_norm_16\")\n",
              "            210 |  # node_silu_25\n",
              "                   %\"silu_25\"<FLOAT,[s13,64,64,64]> ⬅️ ::Mul(%\"group_norm_16\", %\"val_503\")\n",
              "            211 |  # node_conv2d_25\n",
              "                   %\"eps_hat\"<FLOAT,[s13,3,64,64]> ⬅️ ::Conv(%\"silu_25\", %\"conv_out.2.weight\"{...}, %\"conv_out.2.bias\"{[-0.02874157205224037, 0.007491702679544687, -0.004131856840103865]}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
              "            return %\"eps_hat\"<FLOAT,[s13,3,64,64]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_time_mlp_0_weight: \"f32[256, 256]\", p_time_mlp_0_bias: \"f32[256]\", p_time_mlp_2_weight: \"f32[256, 256]\", p_time_mlp_2_bias: \"f32[256]\", p_conv_in_weight: \"f32[64, 7, 3, 3]\", p_conv_in_bias: \"f32[64]\", p_rb1_norm1_weight: \"f32[64]\", p_rb1_norm1_bias: \"f32[64]\", p_rb1_conv1_weight: \"f32[64, 64, 3, 3]\", p_rb1_conv1_bias: \"f32[64]\", p_rb1_norm2_weight: \"f32[64]\", p_rb1_norm2_bias: \"f32[64]\", p_rb1_conv2_weight: \"f32[64, 64, 3, 3]\", p_rb1_conv2_bias: \"f32[64]\", p_rb1_time_proj_1_weight: \"f32[64, 256]\", p_rb1_time_proj_1_bias: \"f32[64]\", p_down1_weight: \"f32[64, 64, 4, 4]\", p_down1_bias: \"f32[64]\", p_rb2_norm1_weight: \"f32[64]\", p_rb2_norm1_bias: \"f32[64]\", p_rb2_conv1_weight: \"f32[128, 64, 3, 3]\", p_rb2_conv1_bias: \"f32[128]\", p_rb2_norm2_weight: \"f32[128]\", p_rb2_norm2_bias: \"f32[128]\", p_rb2_conv2_weight: \"f32[128, 128, 3, 3]\", p_rb2_conv2_bias: \"f32[128]\", p_rb2_time_proj_1_weight: \"f32[128, 256]\", p_rb2_time_proj_1_bias: \"f32[128]\", p_rb2_skip_weight: \"f32[128, 64, 1, 1]\", p_rb2_skip_bias: \"f32[128]\", p_down2_weight: \"f32[128, 128, 4, 4]\", p_down2_bias: \"f32[128]\", p_rb3_norm1_weight: \"f32[128]\", p_rb3_norm1_bias: \"f32[128]\", p_rb3_conv1_weight: \"f32[256, 128, 3, 3]\", p_rb3_conv1_bias: \"f32[256]\", p_rb3_norm2_weight: \"f32[256]\", p_rb3_norm2_bias: \"f32[256]\", p_rb3_conv2_weight: \"f32[256, 256, 3, 3]\", p_rb3_conv2_bias: \"f32[256]\", p_rb3_time_proj_1_weight: \"f32[256, 256]\", p_rb3_time_proj_1_bias: \"f32[256]\", p_rb3_skip_weight: \"f32[256, 128, 1, 1]\", p_rb3_skip_bias: \"f32[256]\", p_down3_weight: \"f32[256, 256, 4, 4]\", p_down3_bias: \"f32[256]\", p_mid1_norm1_weight: \"f32[256]\", p_mid1_norm1_bias: \"f32[256]\", p_mid1_conv1_weight: \"f32[256, 256, 3, 3]\", p_mid1_conv1_bias: \"f32[256]\", p_mid1_norm2_weight: \"f32[256]\", p_mid1_norm2_bias: \"f32[256]\", p_mid1_conv2_weight: \"f32[256, 256, 3, 3]\", p_mid1_conv2_bias: \"f32[256]\", p_mid1_time_proj_1_weight: \"f32[256, 256]\", p_mid1_time_proj_1_bias: \"f32[256]\", p_mid2_norm1_weight: \"f32[256]\", p_mid2_norm1_bias: \"f32[256]\", p_mid2_conv1_weight: \"f32[256, 256, 3, 3]\", p_mid2_conv1_bias: \"f32[256]\", p_mid2_norm2_weight: \"f32[256]\", p_mid2_norm2_bias: \"f32[256]\", p_mid2_conv2_weight: \"f32[256, 256, 3, 3]\", p_mid2_conv2_bias: \"f32[256]\", p_mid2_time_proj_1_weight: \"f32[256, 256]\", p_mid2_time_proj_1_bias: \"f32[256]\", p_up3_weight: \"f32[256, 256, 4, 4]\", p_up3_bias: \"f32[256]\", p_urb3_norm1_weight: \"f32[512]\", p_urb3_norm1_bias: \"f32[512]\", p_urb3_conv1_weight: \"f32[128, 512, 3, 3]\", p_urb3_conv1_bias: \"f32[128]\", p_urb3_norm2_weight: \"f32[128]\", p_urb3_norm2_bias: \"f32[128]\", p_urb3_conv2_weight: \"f32[128, 128, 3, 3]\", p_urb3_conv2_bias: \"f32[128]\", p_urb3_time_proj_1_weight: \"f32[128, 256]\", p_urb3_time_proj_1_bias: \"f32[128]\", p_urb3_skip_weight: \"f32[128, 512, 1, 1]\", p_urb3_skip_bias: \"f32[128]\", p_up2_weight: \"f32[128, 128, 4, 4]\", p_up2_bias: \"f32[128]\", p_urb2_norm1_weight: \"f32[256]\", p_urb2_norm1_bias: \"f32[256]\", p_urb2_conv1_weight: \"f32[64, 256, 3, 3]\", p_urb2_conv1_bias: \"f32[64]\", p_urb2_norm2_weight: \"f32[64]\", p_urb2_norm2_bias: \"f32[64]\", p_urb2_conv2_weight: \"f32[64, 64, 3, 3]\", p_urb2_conv2_bias: \"f32[64]\", p_urb2_time_proj_1_weight: \"f32[64, 256]\", p_urb2_time_proj_1_bias: \"f32[64]\", p_urb2_skip_weight: \"f32[64, 256, 1, 1]\", p_urb2_skip_bias: \"f32[64]\", p_up1_weight: \"f32[64, 64, 4, 4]\", p_up1_bias: \"f32[64]\", p_urb1_norm1_weight: \"f32[128]\", p_urb1_norm1_bias: \"f32[128]\", p_urb1_conv1_weight: \"f32[64, 128, 3, 3]\", p_urb1_conv1_bias: \"f32[64]\", p_urb1_norm2_weight: \"f32[64]\", p_urb1_norm2_bias: \"f32[64]\", p_urb1_conv2_weight: \"f32[64, 64, 3, 3]\", p_urb1_conv2_bias: \"f32[64]\", p_urb1_time_proj_1_weight: \"f32[64, 256]\", p_urb1_time_proj_1_bias: \"f32[64]\", p_urb1_skip_weight: \"f32[64, 128, 1, 1]\", p_urb1_skip_bias: \"f32[64]\", p_conv_out_0_weight: \"f32[64]\", p_conv_out_0_bias: \"f32[64]\", p_conv_out_2_weight: \"f32[3, 64, 3, 3]\", p_conv_out_2_bias: \"f32[3]\", x: \"f32[s13, 7, 64, 64]\", t: \"i64[s13]\"):\n",
              "                     # File: /tmp/ipython-input-3535045203.py:118 in forward, code: t_emb = sinusoidal_time_embedding(t, self.time_dim)\n",
              "                    _to_copy: \"f32[s13]\" = torch.ops.aten._to_copy.default(t, dtype = torch.float32);  t = None\n",
              "                    arange: \"i64[128]\" = torch.ops.aten.arange.default(128, device = device(type='cuda', index=0), pin_memory = False)\n",
              "                    convert_element_type_default: \"f32[128]\" = torch.ops.prims.convert_element_type.default(arange, dtype = torch.float32);  arange = None\n",
              "                    mul_1: \"f32[128]\" = torch.ops.aten.mul.Tensor(convert_element_type_default, -0.07252236513367073);  convert_element_type_default = None\n",
              "                    exp: \"f32[128]\" = torch.ops.aten.exp.default(mul_1);  mul_1 = None\n",
              "                    slice_1: \"f32[s13]\" = torch.ops.aten.slice.Tensor(_to_copy, 0, 0, 9223372036854775807);  _to_copy = None\n",
              "                    unsqueeze: \"f32[s13, 1]\" = torch.ops.aten.unsqueeze.default(slice_1, 1);  slice_1 = None\n",
              "                    unsqueeze_1: \"f32[1, 128]\" = torch.ops.aten.unsqueeze.default(exp, 0);  exp = None\n",
              "                    mul_4: \"f32[s13, 128]\" = torch.ops.aten.mul.Tensor(unsqueeze, unsqueeze_1);  unsqueeze = unsqueeze_1 = None\n",
              "                    sin: \"f32[s13, 128]\" = torch.ops.aten.sin.default(mul_4)\n",
              "                    cos: \"f32[s13, 128]\" = torch.ops.aten.cos.default(mul_4);  mul_4 = None\n",
              "                    cat: \"f32[s13, 256]\" = torch.ops.aten.cat.default([sin, cos], -1);  sin = cos = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[s13, 256]\" = torch.ops.aten.linear.default(cat, p_time_mlp_0_weight, p_time_mlp_0_bias);  cat = p_time_mlp_0_weight = p_time_mlp_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear);  linear = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_1: \"f32[s13, 256]\" = torch.ops.aten.linear.default(silu, p_time_mlp_2_weight, p_time_mlp_2_bias);  silu = p_time_mlp_2_weight = p_time_mlp_2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.conv2d.default(x, p_conv_in_weight, p_conv_in_bias, [1, 1], [1, 1]);  x = p_conv_in_weight = p_conv_in_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.group_norm.default(conv2d, 8, p_rb1_norm1_weight, p_rb1_norm1_bias);  p_rb1_norm1_weight = p_rb1_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_1: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.silu.default(group_norm);  group_norm = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_1: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.conv2d.default(silu_1, p_rb1_conv1_weight, p_rb1_conv1_bias, [1, 1], [1, 1]);  silu_1 = p_rb1_conv1_weight = p_rb1_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_2: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_2: \"f32[s13, 64]\" = torch.ops.aten.linear.default(silu_2, p_rb1_time_proj_1_weight, p_rb1_time_proj_1_bias);  silu_2 = p_rb1_time_proj_1_weight = p_rb1_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_2: \"f32[s13, 64]\" = torch.ops.aten.slice.Tensor(linear_2, 0, 0, 9223372036854775807);  linear_2 = None\n",
              "                    unsqueeze_2: \"f32[s13, 64, 1]\" = torch.ops.aten.unsqueeze.default(slice_2, 2);  slice_2 = None\n",
              "                    unsqueeze_3: \"f32[s13, 64, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_2, 3);  unsqueeze_2 = None\n",
              "                    add_66: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.add.Tensor(conv2d_1, unsqueeze_3);  conv2d_1 = unsqueeze_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_1: \"f32[1, 64, 64, 64]\" = torch.ops.aten.group_norm.default(add_66, 8, p_rb1_norm2_weight, p_rb1_norm2_bias);  add_66 = p_rb1_norm2_weight = p_rb1_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_3: \"f32[1, 64, 64, 64]\" = torch.ops.aten.silu.default(group_norm_1);  group_norm_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_2: \"f32[1, 64, 64, 64]\" = torch.ops.aten.conv2d.default(silu_3, p_rb1_conv2_weight, p_rb1_conv2_bias, [1, 1], [1, 1]);  silu_3 = p_rb1_conv2_weight = p_rb1_conv2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_72: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.add.Tensor(conv2d_2, conv2d);  conv2d_2 = conv2d = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_3: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.conv2d.default(add_72, p_down1_weight, p_down1_bias, [2, 2], [1, 1]);  p_down1_weight = p_down1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_2: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.group_norm.default(conv2d_3, 8, p_rb2_norm1_weight, p_rb2_norm1_bias);  p_rb2_norm1_weight = p_rb2_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_4: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.silu.default(group_norm_2);  group_norm_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_4: \"f32[s13, 128, 32, 32]\" = torch.ops.aten.conv2d.default(silu_4, p_rb2_conv1_weight, p_rb2_conv1_bias, [1, 1], [1, 1]);  silu_4 = p_rb2_conv1_weight = p_rb2_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_5: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_3: \"f32[s13, 128]\" = torch.ops.aten.linear.default(silu_5, p_rb2_time_proj_1_weight, p_rb2_time_proj_1_bias);  silu_5 = p_rb2_time_proj_1_weight = p_rb2_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_3: \"f32[s13, 128]\" = torch.ops.aten.slice.Tensor(linear_3, 0, 0, 9223372036854775807);  linear_3 = None\n",
              "                    unsqueeze_4: \"f32[s13, 128, 1]\" = torch.ops.aten.unsqueeze.default(slice_3, 2);  slice_3 = None\n",
              "                    unsqueeze_5: \"f32[s13, 128, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_4, 3);  unsqueeze_4 = None\n",
              "                    add_116: \"f32[s13, 128, 32, 32]\" = torch.ops.aten.add.Tensor(conv2d_4, unsqueeze_5);  conv2d_4 = unsqueeze_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_3: \"f32[1, 128, 32, 32]\" = torch.ops.aten.group_norm.default(add_116, 8, p_rb2_norm2_weight, p_rb2_norm2_bias);  add_116 = p_rb2_norm2_weight = p_rb2_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_6: \"f32[1, 128, 32, 32]\" = torch.ops.aten.silu.default(group_norm_3);  group_norm_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_5: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(silu_6, p_rb2_conv2_weight, p_rb2_conv2_bias, [1, 1], [1, 1]);  silu_6 = p_rb2_conv2_weight = p_rb2_conv2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_6: \"f32[s13, 128, 32, 32]\" = torch.ops.aten.conv2d.default(conv2d_3, p_rb2_skip_weight, p_rb2_skip_bias);  conv2d_3 = p_rb2_skip_weight = p_rb2_skip_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_127: \"f32[s13, 128, 32, 32]\" = torch.ops.aten.add.Tensor(conv2d_5, conv2d_6);  conv2d_5 = conv2d_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_7: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.conv2d.default(add_127, p_down2_weight, p_down2_bias, [2, 2], [1, 1]);  p_down2_weight = p_down2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_4: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.group_norm.default(conv2d_7, 8, p_rb3_norm1_weight, p_rb3_norm1_bias);  p_rb3_norm1_weight = p_rb3_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_7: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.silu.default(group_norm_4);  group_norm_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_8: \"f32[s13, 256, 16, 16]\" = torch.ops.aten.conv2d.default(silu_7, p_rb3_conv1_weight, p_rb3_conv1_bias, [1, 1], [1, 1]);  silu_7 = p_rb3_conv1_weight = p_rb3_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_8: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_4: \"f32[s13, 256]\" = torch.ops.aten.linear.default(silu_8, p_rb3_time_proj_1_weight, p_rb3_time_proj_1_bias);  silu_8 = p_rb3_time_proj_1_weight = p_rb3_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_4: \"f32[s13, 256]\" = torch.ops.aten.slice.Tensor(linear_4, 0, 0, 9223372036854775807);  linear_4 = None\n",
              "                    unsqueeze_6: \"f32[s13, 256, 1]\" = torch.ops.aten.unsqueeze.default(slice_4, 2);  slice_4 = None\n",
              "                    unsqueeze_7: \"f32[s13, 256, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_6, 3);  unsqueeze_6 = None\n",
              "                    add_171: \"f32[s13, 256, 16, 16]\" = torch.ops.aten.add.Tensor(conv2d_8, unsqueeze_7);  conv2d_8 = unsqueeze_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_5: \"f32[1, 256, 16, 16]\" = torch.ops.aten.group_norm.default(add_171, 8, p_rb3_norm2_weight, p_rb3_norm2_bias);  add_171 = p_rb3_norm2_weight = p_rb3_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_9: \"f32[1, 256, 16, 16]\" = torch.ops.aten.silu.default(group_norm_5);  group_norm_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_9: \"f32[1, 256, 16, 16]\" = torch.ops.aten.conv2d.default(silu_9, p_rb3_conv2_weight, p_rb3_conv2_bias, [1, 1], [1, 1]);  silu_9 = p_rb3_conv2_weight = p_rb3_conv2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_10: \"f32[s13, 256, 16, 16]\" = torch.ops.aten.conv2d.default(conv2d_7, p_rb3_skip_weight, p_rb3_skip_bias);  conv2d_7 = p_rb3_skip_weight = p_rb3_skip_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_182: \"f32[s13, 256, 16, 16]\" = torch.ops.aten.add.Tensor(conv2d_9, conv2d_10);  conv2d_9 = conv2d_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_11: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.conv2d.default(add_182, p_down3_weight, p_down3_bias, [2, 2], [1, 1]);  p_down3_weight = p_down3_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_6: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.group_norm.default(conv2d_11, 8, p_mid1_norm1_weight, p_mid1_norm1_bias);  p_mid1_norm1_weight = p_mid1_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_10: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.silu.default(group_norm_6);  group_norm_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_12: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.conv2d.default(silu_10, p_mid1_conv1_weight, p_mid1_conv1_bias, [1, 1], [1, 1]);  silu_10 = p_mid1_conv1_weight = p_mid1_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_11: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_5: \"f32[s13, 256]\" = torch.ops.aten.linear.default(silu_11, p_mid1_time_proj_1_weight, p_mid1_time_proj_1_bias);  silu_11 = p_mid1_time_proj_1_weight = p_mid1_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_5: \"f32[s13, 256]\" = torch.ops.aten.slice.Tensor(linear_5, 0, 0, 9223372036854775807);  linear_5 = None\n",
              "                    unsqueeze_8: \"f32[s13, 256, 1]\" = torch.ops.aten.unsqueeze.default(slice_5, 2);  slice_5 = None\n",
              "                    unsqueeze_9: \"f32[s13, 256, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_8, 3);  unsqueeze_8 = None\n",
              "                    add_226: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.add.Tensor(conv2d_12, unsqueeze_9);  conv2d_12 = unsqueeze_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_7: \"f32[1, 256, 8, 8]\" = torch.ops.aten.group_norm.default(add_226, 8, p_mid1_norm2_weight, p_mid1_norm2_bias);  add_226 = p_mid1_norm2_weight = p_mid1_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_12: \"f32[1, 256, 8, 8]\" = torch.ops.aten.silu.default(group_norm_7);  group_norm_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_13: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(silu_12, p_mid1_conv2_weight, p_mid1_conv2_bias, [1, 1], [1, 1]);  silu_12 = p_mid1_conv2_weight = p_mid1_conv2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_232: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.add.Tensor(conv2d_13, conv2d_11);  conv2d_13 = conv2d_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_8: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.group_norm.default(add_232, 8, p_mid2_norm1_weight, p_mid2_norm1_bias);  p_mid2_norm1_weight = p_mid2_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_13: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.silu.default(group_norm_8);  group_norm_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_14: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.conv2d.default(silu_13, p_mid2_conv1_weight, p_mid2_conv1_bias, [1, 1], [1, 1]);  silu_13 = p_mid2_conv1_weight = p_mid2_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_14: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_6: \"f32[s13, 256]\" = torch.ops.aten.linear.default(silu_14, p_mid2_time_proj_1_weight, p_mid2_time_proj_1_bias);  silu_14 = p_mid2_time_proj_1_weight = p_mid2_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_6: \"f32[s13, 256]\" = torch.ops.aten.slice.Tensor(linear_6, 0, 0, 9223372036854775807);  linear_6 = None\n",
              "                    unsqueeze_10: \"f32[s13, 256, 1]\" = torch.ops.aten.unsqueeze.default(slice_6, 2);  slice_6 = None\n",
              "                    unsqueeze_11: \"f32[s13, 256, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_10, 3);  unsqueeze_10 = None\n",
              "                    add_271: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.add.Tensor(conv2d_14, unsqueeze_11);  conv2d_14 = unsqueeze_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_9: \"f32[1, 256, 8, 8]\" = torch.ops.aten.group_norm.default(add_271, 8, p_mid2_norm2_weight, p_mid2_norm2_bias);  add_271 = p_mid2_norm2_weight = p_mid2_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_15: \"f32[1, 256, 8, 8]\" = torch.ops.aten.silu.default(group_norm_9);  group_norm_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_15: \"f32[1, 256, 8, 8]\" = torch.ops.aten.conv2d.default(silu_15, p_mid2_conv2_weight, p_mid2_conv2_bias, [1, 1], [1, 1]);  silu_15 = p_mid2_conv2_weight = p_mid2_conv2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_277: \"f32[s13, 256, 8, 8]\" = torch.ops.aten.add.Tensor(conv2d_15, add_232);  conv2d_15 = add_232 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:1161 in forward, code: return F.conv_transpose2d(\n",
              "                    convolution: \"f32[s13, 256, 16, 16]\" = torch.ops.aten.convolution.default(add_277, p_up3_weight, p_up3_bias, [2, 2], [1, 1], [1, 1], True, [0, 0], 1);  add_277 = p_up3_weight = p_up3_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:135 in forward, code: u3 = torch.cat([u3, x3], dim=1)\n",
              "                    cat_1: \"f32[s13, 512, 16, 16]\" = torch.ops.aten.cat.default([convolution, add_182], 1);  convolution = add_182 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_10: \"f32[s13, 512, 16, 16]\" = torch.ops.aten.group_norm.default(cat_1, 8, p_urb3_norm1_weight, p_urb3_norm1_bias);  p_urb3_norm1_weight = p_urb3_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_16: \"f32[s13, 512, 16, 16]\" = torch.ops.aten.silu.default(group_norm_10);  group_norm_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_16: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.conv2d.default(silu_16, p_urb3_conv1_weight, p_urb3_conv1_bias, [1, 1], [1, 1]);  silu_16 = p_urb3_conv1_weight = p_urb3_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_17: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_7: \"f32[s13, 128]\" = torch.ops.aten.linear.default(silu_17, p_urb3_time_proj_1_weight, p_urb3_time_proj_1_bias);  silu_17 = p_urb3_time_proj_1_weight = p_urb3_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_7: \"f32[s13, 128]\" = torch.ops.aten.slice.Tensor(linear_7, 0, 0, 9223372036854775807);  linear_7 = None\n",
              "                    unsqueeze_12: \"f32[s13, 128, 1]\" = torch.ops.aten.unsqueeze.default(slice_7, 2);  slice_7 = None\n",
              "                    unsqueeze_13: \"f32[s13, 128, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_12, 3);  unsqueeze_12 = None\n",
              "                    add_326: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.add.Tensor(conv2d_16, unsqueeze_13);  conv2d_16 = unsqueeze_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_11: \"f32[1, 128, 16, 16]\" = torch.ops.aten.group_norm.default(add_326, 8, p_urb3_norm2_weight, p_urb3_norm2_bias);  add_326 = p_urb3_norm2_weight = p_urb3_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_18: \"f32[1, 128, 16, 16]\" = torch.ops.aten.silu.default(group_norm_11);  group_norm_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_17: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(silu_18, p_urb3_conv2_weight, p_urb3_conv2_bias, [1, 1], [1, 1]);  silu_18 = p_urb3_conv2_weight = p_urb3_conv2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_18: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.conv2d.default(cat_1, p_urb3_skip_weight, p_urb3_skip_bias);  cat_1 = p_urb3_skip_weight = p_urb3_skip_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_337: \"f32[s13, 128, 16, 16]\" = torch.ops.aten.add.Tensor(conv2d_17, conv2d_18);  conv2d_17 = conv2d_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:1161 in forward, code: return F.conv_transpose2d(\n",
              "                    convolution_1: \"f32[s13, 128, 32, 32]\" = torch.ops.aten.convolution.default(add_337, p_up2_weight, p_up2_bias, [2, 2], [1, 1], [1, 1], True, [0, 0], 1);  add_337 = p_up2_weight = p_up2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:139 in forward, code: u2 = torch.cat([u2, x2], dim=1)\n",
              "                    cat_2: \"f32[s13, 256, 32, 32]\" = torch.ops.aten.cat.default([convolution_1, add_127], 1);  convolution_1 = add_127 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_12: \"f32[s13, 256, 32, 32]\" = torch.ops.aten.group_norm.default(cat_2, 8, p_urb2_norm1_weight, p_urb2_norm1_bias);  p_urb2_norm1_weight = p_urb2_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_19: \"f32[s13, 256, 32, 32]\" = torch.ops.aten.silu.default(group_norm_12);  group_norm_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_19: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.conv2d.default(silu_19, p_urb2_conv1_weight, p_urb2_conv1_bias, [1, 1], [1, 1]);  silu_19 = p_urb2_conv1_weight = p_urb2_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_20: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_8: \"f32[s13, 64]\" = torch.ops.aten.linear.default(silu_20, p_urb2_time_proj_1_weight, p_urb2_time_proj_1_bias);  silu_20 = p_urb2_time_proj_1_weight = p_urb2_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_8: \"f32[s13, 64]\" = torch.ops.aten.slice.Tensor(linear_8, 0, 0, 9223372036854775807);  linear_8 = None\n",
              "                    unsqueeze_14: \"f32[s13, 64, 1]\" = torch.ops.aten.unsqueeze.default(slice_8, 2);  slice_8 = None\n",
              "                    unsqueeze_15: \"f32[s13, 64, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_14, 3);  unsqueeze_14 = None\n",
              "                    add_386: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.add.Tensor(conv2d_19, unsqueeze_15);  conv2d_19 = unsqueeze_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_13: \"f32[1, 64, 32, 32]\" = torch.ops.aten.group_norm.default(add_386, 8, p_urb2_norm2_weight, p_urb2_norm2_bias);  add_386 = p_urb2_norm2_weight = p_urb2_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_21: \"f32[1, 64, 32, 32]\" = torch.ops.aten.silu.default(group_norm_13);  group_norm_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_20: \"f32[1, 64, 32, 32]\" = torch.ops.aten.conv2d.default(silu_21, p_urb2_conv2_weight, p_urb2_conv2_bias, [1, 1], [1, 1]);  silu_21 = p_urb2_conv2_weight = p_urb2_conv2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_21: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.conv2d.default(cat_2, p_urb2_skip_weight, p_urb2_skip_bias);  cat_2 = p_urb2_skip_weight = p_urb2_skip_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_397: \"f32[s13, 64, 32, 32]\" = torch.ops.aten.add.Tensor(conv2d_20, conv2d_21);  conv2d_20 = conv2d_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:1161 in forward, code: return F.conv_transpose2d(\n",
              "                    convolution_2: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.convolution.default(add_397, p_up1_weight, p_up1_bias, [2, 2], [1, 1], [1, 1], True, [0, 0], 1);  add_397 = p_up1_weight = p_up1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:143 in forward, code: u1 = torch.cat([u1, x1], dim=1)\n",
              "                    cat_3: \"f32[s13, 128, 64, 64]\" = torch.ops.aten.cat.default([convolution_2, add_72], 1);  convolution_2 = add_72 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_14: \"f32[s13, 128, 64, 64]\" = torch.ops.aten.group_norm.default(cat_3, 8, p_urb1_norm1_weight, p_urb1_norm1_bias);  p_urb1_norm1_weight = p_urb1_norm1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:66 in forward, code: h = self.conv1(F.silu(self.norm1(x))) # Silu (that are more common in diffusion models) instead of Relu\n",
              "                    silu_22: \"f32[s13, 128, 64, 64]\" = torch.ops.aten.silu.default(group_norm_14);  group_norm_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_22: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.conv2d.default(silu_22, p_urb1_conv1_weight, p_urb1_conv1_bias, [1, 1], [1, 1]);  silu_22 = p_urb1_conv1_weight = p_urb1_conv1_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_23: \"f32[s13, 256]\" = torch.ops.aten.silu.default(linear_1);  linear_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_9: \"f32[s13, 64]\" = torch.ops.aten.linear.default(silu_23, p_urb1_time_proj_1_weight, p_urb1_time_proj_1_bias);  silu_23 = p_urb1_time_proj_1_weight = p_urb1_time_proj_1_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:68 in forward, code: h = h + self.time_proj(t_emb)[:, :, None, None]\n",
              "                    slice_9: \"f32[s13, 64]\" = torch.ops.aten.slice.Tensor(linear_9, 0, 0, 9223372036854775807);  linear_9 = None\n",
              "                    unsqueeze_16: \"f32[s13, 64, 1]\" = torch.ops.aten.unsqueeze.default(slice_9, 2);  slice_9 = None\n",
              "                    unsqueeze_17: \"f32[s13, 64, 1, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_16, 3);  unsqueeze_16 = None\n",
              "                    add_446: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.add.Tensor(conv2d_22, unsqueeze_17);  conv2d_22 = unsqueeze_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_15: \"f32[1, 64, 64, 64]\" = torch.ops.aten.group_norm.default(add_446, 8, p_urb1_norm2_weight, p_urb1_norm2_bias);  add_446 = p_urb1_norm2_weight = p_urb1_norm2_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:69 in forward, code: h = self.conv2(F.silu(self.norm2(h)))\n",
              "                    silu_24: \"f32[1, 64, 64, 64]\" = torch.ops.aten.silu.default(group_norm_15);  group_norm_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_23: \"f32[1, 64, 64, 64]\" = torch.ops.aten.conv2d.default(silu_24, p_urb1_conv2_weight, p_urb1_conv2_bias, [1, 1], [1, 1]);  silu_24 = p_urb1_conv2_weight = p_urb1_conv2_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_24: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.conv2d.default(cat_3, p_urb1_skip_weight, p_urb1_skip_bias);  cat_3 = p_urb1_skip_weight = p_urb1_skip_bias = None\n",
              "            \n",
              "                     # File: /tmp/ipython-input-3535045203.py:70 in forward, code: return h + self.skip(x)\n",
              "                    add_457: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.add.Tensor(conv2d_23, conv2d_24);  conv2d_23 = conv2d_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:325 in forward, code: return F.group_norm(input, self.num_groups, self.weight, self.bias, self.eps)\n",
              "                    group_norm_16: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.group_norm.default(add_457, 8, p_conv_out_0_weight, p_conv_out_0_bias);  add_457 = p_conv_out_0_weight = p_conv_out_0_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
              "                    silu_25: \"f32[s13, 64, 64, 64]\" = torch.ops.aten.silu.default(group_norm_16);  group_norm_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
              "                    conv2d_25: \"f32[s13, 3, 64, 64]\" = torch.ops.aten.conv2d.default(silu_25, p_conv_out_2_weight, p_conv_out_2_bias, [1, 1], [1, 1]);  silu_25 = p_conv_out_2_weight = p_conv_out_2_bias = None\n",
              "                    return (conv2d_25,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_time_mlp_0_weight: PARAMETER target='time_mlp.0.weight'\n",
              "            p_time_mlp_0_bias: PARAMETER target='time_mlp.0.bias'\n",
              "            p_time_mlp_2_weight: PARAMETER target='time_mlp.2.weight'\n",
              "            p_time_mlp_2_bias: PARAMETER target='time_mlp.2.bias'\n",
              "            p_conv_in_weight: PARAMETER target='conv_in.weight'\n",
              "            p_conv_in_bias: PARAMETER target='conv_in.bias'\n",
              "            p_rb1_norm1_weight: PARAMETER target='rb1.norm1.weight'\n",
              "            p_rb1_norm1_bias: PARAMETER target='rb1.norm1.bias'\n",
              "            p_rb1_conv1_weight: PARAMETER target='rb1.conv1.weight'\n",
              "            p_rb1_conv1_bias: PARAMETER target='rb1.conv1.bias'\n",
              "            p_rb1_norm2_weight: PARAMETER target='rb1.norm2.weight'\n",
              "            p_rb1_norm2_bias: PARAMETER target='rb1.norm2.bias'\n",
              "            p_rb1_conv2_weight: PARAMETER target='rb1.conv2.weight'\n",
              "            p_rb1_conv2_bias: PARAMETER target='rb1.conv2.bias'\n",
              "            p_rb1_time_proj_1_weight: PARAMETER target='rb1.time_proj.1.weight'\n",
              "            p_rb1_time_proj_1_bias: PARAMETER target='rb1.time_proj.1.bias'\n",
              "            p_down1_weight: PARAMETER target='down1.weight'\n",
              "            p_down1_bias: PARAMETER target='down1.bias'\n",
              "            p_rb2_norm1_weight: PARAMETER target='rb2.norm1.weight'\n",
              "            p_rb2_norm1_bias: PARAMETER target='rb2.norm1.bias'\n",
              "            p_rb2_conv1_weight: PARAMETER target='rb2.conv1.weight'\n",
              "            p_rb2_conv1_bias: PARAMETER target='rb2.conv1.bias'\n",
              "            p_rb2_norm2_weight: PARAMETER target='rb2.norm2.weight'\n",
              "            p_rb2_norm2_bias: PARAMETER target='rb2.norm2.bias'\n",
              "            p_rb2_conv2_weight: PARAMETER target='rb2.conv2.weight'\n",
              "            p_rb2_conv2_bias: PARAMETER target='rb2.conv2.bias'\n",
              "            p_rb2_time_proj_1_weight: PARAMETER target='rb2.time_proj.1.weight'\n",
              "            p_rb2_time_proj_1_bias: PARAMETER target='rb2.time_proj.1.bias'\n",
              "            p_rb2_skip_weight: PARAMETER target='rb2.skip.weight'\n",
              "            p_rb2_skip_bias: PARAMETER target='rb2.skip.bias'\n",
              "            p_down2_weight: PARAMETER target='down2.weight'\n",
              "            p_down2_bias: PARAMETER target='down2.bias'\n",
              "            p_rb3_norm1_weight: PARAMETER target='rb3.norm1.weight'\n",
              "            p_rb3_norm1_bias: PARAMETER target='rb3.norm1.bias'\n",
              "            p_rb3_conv1_weight: PARAMETER target='rb3.conv1.weight'\n",
              "            p_rb3_conv1_bias: PARAMETER target='rb3.conv1.bias'\n",
              "            p_rb3_norm2_weight: PARAMETER target='rb3.norm2.weight'\n",
              "            p_rb3_norm2_bias: PARAMETER target='rb3.norm2.bias'\n",
              "            p_rb3_conv2_weight: PARAMETER target='rb3.conv2.weight'\n",
              "            p_rb3_conv2_bias: PARAMETER target='rb3.conv2.bias'\n",
              "            p_rb3_time_proj_1_weight: PARAMETER target='rb3.time_proj.1.weight'\n",
              "            p_rb3_time_proj_1_bias: PARAMETER target='rb3.time_proj.1.bias'\n",
              "            p_rb3_skip_weight: PARAMETER target='rb3.skip.weight'\n",
              "            p_rb3_skip_bias: PARAMETER target='rb3.skip.bias'\n",
              "            p_down3_weight: PARAMETER target='down3.weight'\n",
              "            p_down3_bias: PARAMETER target='down3.bias'\n",
              "            p_mid1_norm1_weight: PARAMETER target='mid1.norm1.weight'\n",
              "            p_mid1_norm1_bias: PARAMETER target='mid1.norm1.bias'\n",
              "            p_mid1_conv1_weight: PARAMETER target='mid1.conv1.weight'\n",
              "            p_mid1_conv1_bias: PARAMETER target='mid1.conv1.bias'\n",
              "            p_mid1_norm2_weight: PARAMETER target='mid1.norm2.weight'\n",
              "            p_mid1_norm2_bias: PARAMETER target='mid1.norm2.bias'\n",
              "            p_mid1_conv2_weight: PARAMETER target='mid1.conv2.weight'\n",
              "            p_mid1_conv2_bias: PARAMETER target='mid1.conv2.bias'\n",
              "            p_mid1_time_proj_1_weight: PARAMETER target='mid1.time_proj.1.weight'\n",
              "            p_mid1_time_proj_1_bias: PARAMETER target='mid1.time_proj.1.bias'\n",
              "            p_mid2_norm1_weight: PARAMETER target='mid2.norm1.weight'\n",
              "            p_mid2_norm1_bias: PARAMETER target='mid2.norm1.bias'\n",
              "            p_mid2_conv1_weight: PARAMETER target='mid2.conv1.weight'\n",
              "            p_mid2_conv1_bias: PARAMETER target='mid2.conv1.bias'\n",
              "            p_mid2_norm2_weight: PARAMETER target='mid2.norm2.weight'\n",
              "            p_mid2_norm2_bias: PARAMETER target='mid2.norm2.bias'\n",
              "            p_mid2_conv2_weight: PARAMETER target='mid2.conv2.weight'\n",
              "            p_mid2_conv2_bias: PARAMETER target='mid2.conv2.bias'\n",
              "            p_mid2_time_proj_1_weight: PARAMETER target='mid2.time_proj.1.weight'\n",
              "            p_mid2_time_proj_1_bias: PARAMETER target='mid2.time_proj.1.bias'\n",
              "            p_up3_weight: PARAMETER target='up3.weight'\n",
              "            p_up3_bias: PARAMETER target='up3.bias'\n",
              "            p_urb3_norm1_weight: PARAMETER target='urb3.norm1.weight'\n",
              "            p_urb3_norm1_bias: PARAMETER target='urb3.norm1.bias'\n",
              "            p_urb3_conv1_weight: PARAMETER target='urb3.conv1.weight'\n",
              "            p_urb3_conv1_bias: PARAMETER target='urb3.conv1.bias'\n",
              "            p_urb3_norm2_weight: PARAMETER target='urb3.norm2.weight'\n",
              "            p_urb3_norm2_bias: PARAMETER target='urb3.norm2.bias'\n",
              "            p_urb3_conv2_weight: PARAMETER target='urb3.conv2.weight'\n",
              "            p_urb3_conv2_bias: PARAMETER target='urb3.conv2.bias'\n",
              "            p_urb3_time_proj_1_weight: PARAMETER target='urb3.time_proj.1.weight'\n",
              "            p_urb3_time_proj_1_bias: PARAMETER target='urb3.time_proj.1.bias'\n",
              "            p_urb3_skip_weight: PARAMETER target='urb3.skip.weight'\n",
              "            p_urb3_skip_bias: PARAMETER target='urb3.skip.bias'\n",
              "            p_up2_weight: PARAMETER target='up2.weight'\n",
              "            p_up2_bias: PARAMETER target='up2.bias'\n",
              "            p_urb2_norm1_weight: PARAMETER target='urb2.norm1.weight'\n",
              "            p_urb2_norm1_bias: PARAMETER target='urb2.norm1.bias'\n",
              "            p_urb2_conv1_weight: PARAMETER target='urb2.conv1.weight'\n",
              "            p_urb2_conv1_bias: PARAMETER target='urb2.conv1.bias'\n",
              "            p_urb2_norm2_weight: PARAMETER target='urb2.norm2.weight'\n",
              "            p_urb2_norm2_bias: PARAMETER target='urb2.norm2.bias'\n",
              "            p_urb2_conv2_weight: PARAMETER target='urb2.conv2.weight'\n",
              "            p_urb2_conv2_bias: PARAMETER target='urb2.conv2.bias'\n",
              "            p_urb2_time_proj_1_weight: PARAMETER target='urb2.time_proj.1.weight'\n",
              "            p_urb2_time_proj_1_bias: PARAMETER target='urb2.time_proj.1.bias'\n",
              "            p_urb2_skip_weight: PARAMETER target='urb2.skip.weight'\n",
              "            p_urb2_skip_bias: PARAMETER target='urb2.skip.bias'\n",
              "            p_up1_weight: PARAMETER target='up1.weight'\n",
              "            p_up1_bias: PARAMETER target='up1.bias'\n",
              "            p_urb1_norm1_weight: PARAMETER target='urb1.norm1.weight'\n",
              "            p_urb1_norm1_bias: PARAMETER target='urb1.norm1.bias'\n",
              "            p_urb1_conv1_weight: PARAMETER target='urb1.conv1.weight'\n",
              "            p_urb1_conv1_bias: PARAMETER target='urb1.conv1.bias'\n",
              "            p_urb1_norm2_weight: PARAMETER target='urb1.norm2.weight'\n",
              "            p_urb1_norm2_bias: PARAMETER target='urb1.norm2.bias'\n",
              "            p_urb1_conv2_weight: PARAMETER target='urb1.conv2.weight'\n",
              "            p_urb1_conv2_bias: PARAMETER target='urb1.conv2.bias'\n",
              "            p_urb1_time_proj_1_weight: PARAMETER target='urb1.time_proj.1.weight'\n",
              "            p_urb1_time_proj_1_bias: PARAMETER target='urb1.time_proj.1.bias'\n",
              "            p_urb1_skip_weight: PARAMETER target='urb1.skip.weight'\n",
              "            p_urb1_skip_bias: PARAMETER target='urb1.skip.bias'\n",
              "            p_conv_out_0_weight: PARAMETER target='conv_out.0.weight'\n",
              "            p_conv_out_0_bias: PARAMETER target='conv_out.0.bias'\n",
              "            p_conv_out_2_weight: PARAMETER target='conv_out.2.weight'\n",
              "            p_conv_out_2_bias: PARAMETER target='conv_out.2.bias'\n",
              "            x: USER_INPUT\n",
              "            t: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            conv2d_25: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {s13: VR[0, int_oo]}\n",
              "\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}